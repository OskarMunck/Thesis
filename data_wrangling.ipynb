{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File for creating more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# NLP libs\n",
    "import spacy, nltk, gensim, sklearn\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# meta_data = pd.read_csv(\"metadata.tsv\", sep = \"/t\")\n",
    "# meta_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"show_name\", \"show_description\", \"publisher\", \"language\", \"episode_name\", \"episode_description\", \"duration\"]\n",
    "features_df = meta_data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OBS: TAKES A LOT OF TIME! Approx. 60 min\n",
    "# Make spacy objects according to English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# spacy_obj = [nlp(i) for i in features_df.episode_description]\n",
    "features_df[\"eps_nlp\"] = spacy_obj\n",
    "# spacy_obj_show = [nlp(i) for i in features_df.show_description]\n",
    "features_df[\"show_nlp\"] = spacy_obj_show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenise episodes\n",
    "eps_tokens_all = []\n",
    "for episode in features_df.eps_nlp:\n",
    "    eps_tokens_all.append([tok.text for tok in episode])\n",
    "\n",
    "features_df[\"episode_tokens\"] = eps_tokens_all\n",
    "\n",
    "print(features_df.eps_nlp[0])\n",
    "print(features_df.episode_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenise show\n",
    "eps_tokens_all_show = []\n",
    "for show in features_df.eps_nlp:\n",
    "    eps_tokens_all_show.append([tok.text for tok in show])\n",
    "\n",
    "features_df[\"show_tokens\"] = eps_tokens_all_show\n",
    "\n",
    "print(features_df.show_nlp[0])\n",
    "print(features_df.show_tokens[0])\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add word count features\n",
    "# Epsiode desc\n",
    "eps_word_count = []\n",
    "for desc in features_df.episode_tokens:\n",
    "    eps_word_count.append(len(desc))\n",
    "\n",
    "features_df[\"eps_word_count\"] = eps_word_count\n",
    "\n",
    "# Show desc\n",
    "show_word_count = []\n",
    "for desc in features_df.episode_tokens:\n",
    "    show_word_count.append(len(desc))\n",
    "\n",
    "features_df[\"show_word_count\"] = show_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis\n",
    "sent_analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment(text, choice):\n",
    "    scores = sent_analyser.polarity_scores(text)\n",
    "    return scores[choice]\n",
    "\n",
    "features_nlp[\"positive_score_eps\"] = features_nlp.episode_description.apply(lambda x: sentiment(x, \"pos\"))\n",
    "features_nlp[\"negative_score_eps\"] = features_nlp.episode_description.apply(lambda x: sentiment(x, \"neg\"))\n",
    "features_nlp[\"neutral_score_eps\"] = features_nlp.episode_description.apply(lambda x: sentiment(x, \"neu\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Up until this point, the metadata_features dataset is constructed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_nlp = pd.read_csv('metadata_features.csv.gz', sep = \",\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_name</th>\n",
       "      <th>show_description</th>\n",
       "      <th>publisher</th>\n",
       "      <th>language</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>episode_description</th>\n",
       "      <th>duration</th>\n",
       "      <th>episode_description_clean</th>\n",
       "      <th>eps_nlp</th>\n",
       "      <th>episode_tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>show_nlp</th>\n",
       "      <th>show_tokens</th>\n",
       "      <th>eps_word_count</th>\n",
       "      <th>show_word_count</th>\n",
       "      <th>positive_score_eps</th>\n",
       "      <th>negative_score_eps</th>\n",
       "      <th>neutral_score_eps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kream in your Koffee</td>\n",
       "      <td>A 20-something blunt female takes on the world...</td>\n",
       "      <td>Katie Houle</td>\n",
       "      <td>['en']</td>\n",
       "      <td>1: It’s Christmas Time!</td>\n",
       "      <td>On the first ever episode of Kream in your Kof...</td>\n",
       "      <td>12.700133</td>\n",
       "      <td>On the first ever episode of Kream in your Kof...</td>\n",
       "      <td>On the first ever episode of Kream in your Kof...</td>\n",
       "      <td>['On', 'the', 'first', 'ever', 'episode', 'of'...</td>\n",
       "      <td>39</td>\n",
       "      <td>A 20-something blunt female takes on the world...</td>\n",
       "      <td>['On', 'the', 'first', 'ever', 'episode', 'of'...</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morning Cup Of Murder</td>\n",
       "      <td>Ever wonder what murder took place on today in...</td>\n",
       "      <td>Morning Cup Of Murder</td>\n",
       "      <td>['en']</td>\n",
       "      <td>The Goleta Postal Facility shootings- January ...</td>\n",
       "      <td>See something, say something. It’s a mantra ma...</td>\n",
       "      <td>6.019383</td>\n",
       "      <td>See something, say something. It’s a mantra ma...</td>\n",
       "      <td>See something, say something. It’s a mantra ma...</td>\n",
       "      <td>['See', 'something', ',', 'say', 'something', ...</td>\n",
       "      <td>171</td>\n",
       "      <td>Ever wonder what murder took place on today in...</td>\n",
       "      <td>['See', 'something', ',', 'say', 'something', ...</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inside The 18 : A Podcast for Goalkeepers by G...</td>\n",
       "      <td>Inside the 18 is your source for all things Go...</td>\n",
       "      <td>Inside the 18 GK Media</td>\n",
       "      <td>['en']</td>\n",
       "      <td>Ep.36 - Incorporating a Singular Goalkeeping C...</td>\n",
       "      <td>Today’s episode is a sit down Michael and Omar...</td>\n",
       "      <td>43.616333</td>\n",
       "      <td>Today’s episode is a sit down Michael and Omar...</td>\n",
       "      <td>Today’s episode is a sit down Michael and Omar...</td>\n",
       "      <td>['Today', '’s', 'episode', 'is', 'a', 'sit', '...</td>\n",
       "      <td>115</td>\n",
       "      <td>Inside the 18 is your source for all things Go...</td>\n",
       "      <td>['Today', '’s', 'episode', 'is', 'a', 'sit', '...</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arrowhead Live!</td>\n",
       "      <td>Your favorite podcast for everything @Chiefs! ...</td>\n",
       "      <td>Arrowhead Live!</td>\n",
       "      <td>['en-US']</td>\n",
       "      <td>Episode 1: Arrowhead Live! Debut</td>\n",
       "      <td>Join us as we take a look at all current Chief...</td>\n",
       "      <td>58.189200</td>\n",
       "      <td>Join us as we take a look at all current Chief...</td>\n",
       "      <td>Join us as we take a look at all current Chief...</td>\n",
       "      <td>['Join', 'us', 'as', 'we', 'take', 'a', 'look'...</td>\n",
       "      <td>52</td>\n",
       "      <td>Your favorite podcast for everything @Chiefs! ...</td>\n",
       "      <td>['Join', 'us', 'as', 'we', 'take', 'a', 'look'...</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FBoL</td>\n",
       "      <td>The comedy podcast about toxic characters, wri...</td>\n",
       "      <td>Emily Edwards</td>\n",
       "      <td>['en']</td>\n",
       "      <td>The Lion, The Witch, And The Wardrobe - Ashley...</td>\n",
       "      <td>The modern morality tail of how to stay good f...</td>\n",
       "      <td>51.782050</td>\n",
       "      <td>The modern morality tail of how to stay good f...</td>\n",
       "      <td>The modern morality tail of how to stay good f...</td>\n",
       "      <td>['The', 'modern', 'morality', 'tail', 'of', 'h...</td>\n",
       "      <td>88</td>\n",
       "      <td>The comedy podcast about toxic characters, wri...</td>\n",
       "      <td>['The', 'modern', 'morality', 'tail', 'of', 'h...</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           show_name  \\\n",
       "0                               Kream in your Koffee   \n",
       "1                              Morning Cup Of Murder   \n",
       "2  Inside The 18 : A Podcast for Goalkeepers by G...   \n",
       "3                                    Arrowhead Live!   \n",
       "4                                              FBoL    \n",
       "\n",
       "                                    show_description               publisher  \\\n",
       "0  A 20-something blunt female takes on the world...             Katie Houle   \n",
       "1  Ever wonder what murder took place on today in...   Morning Cup Of Murder   \n",
       "2  Inside the 18 is your source for all things Go...  Inside the 18 GK Media   \n",
       "3  Your favorite podcast for everything @Chiefs! ...         Arrowhead Live!   \n",
       "4  The comedy podcast about toxic characters, wri...           Emily Edwards   \n",
       "\n",
       "    language                                       episode_name  \\\n",
       "0     ['en']                            1: It’s Christmas Time!   \n",
       "1     ['en']  The Goleta Postal Facility shootings- January ...   \n",
       "2     ['en']  Ep.36 - Incorporating a Singular Goalkeeping C...   \n",
       "3  ['en-US']                   Episode 1: Arrowhead Live! Debut   \n",
       "4     ['en']  The Lion, The Witch, And The Wardrobe - Ashley...   \n",
       "\n",
       "                                 episode_description   duration  \\\n",
       "0  On the first ever episode of Kream in your Kof...  12.700133   \n",
       "1  See something, say something. It’s a mantra ma...   6.019383   \n",
       "2  Today’s episode is a sit down Michael and Omar...  43.616333   \n",
       "3  Join us as we take a look at all current Chief...  58.189200   \n",
       "4  The modern morality tail of how to stay good f...  51.782050   \n",
       "\n",
       "                           episode_description_clean  \\\n",
       "0  On the first ever episode of Kream in your Kof...   \n",
       "1  See something, say something. It’s a mantra ma...   \n",
       "2  Today’s episode is a sit down Michael and Omar...   \n",
       "3  Join us as we take a look at all current Chief...   \n",
       "4  The modern morality tail of how to stay good f...   \n",
       "\n",
       "                                             eps_nlp  \\\n",
       "0  On the first ever episode of Kream in your Kof...   \n",
       "1  See something, say something. It’s a mantra ma...   \n",
       "2  Today’s episode is a sit down Michael and Omar...   \n",
       "3  Join us as we take a look at all current Chief...   \n",
       "4  The modern morality tail of how to stay good f...   \n",
       "\n",
       "                                      episode_tokens  word_count  \\\n",
       "0  ['On', 'the', 'first', 'ever', 'episode', 'of'...          39   \n",
       "1  ['See', 'something', ',', 'say', 'something', ...         171   \n",
       "2  ['Today', '’s', 'episode', 'is', 'a', 'sit', '...         115   \n",
       "3  ['Join', 'us', 'as', 'we', 'take', 'a', 'look'...          52   \n",
       "4  ['The', 'modern', 'morality', 'tail', 'of', 'h...          88   \n",
       "\n",
       "                                            show_nlp  \\\n",
       "0  A 20-something blunt female takes on the world...   \n",
       "1  Ever wonder what murder took place on today in...   \n",
       "2  Inside the 18 is your source for all things Go...   \n",
       "3  Your favorite podcast for everything @Chiefs! ...   \n",
       "4  The comedy podcast about toxic characters, wri...   \n",
       "\n",
       "                                         show_tokens  eps_word_count  \\\n",
       "0  ['On', 'the', 'first', 'ever', 'episode', 'of'...              39   \n",
       "1  ['See', 'something', ',', 'say', 'something', ...             171   \n",
       "2  ['Today', '’s', 'episode', 'is', 'a', 'sit', '...             115   \n",
       "3  ['Join', 'us', 'as', 'we', 'take', 'a', 'look'...              52   \n",
       "4  ['The', 'modern', 'morality', 'tail', 'of', 'h...              88   \n",
       "\n",
       "   show_word_count  positive_score_eps  negative_score_eps  neutral_score_eps  \n",
       "0               39               0.000               0.000              1.000  \n",
       "1              171               0.087               0.220              0.693  \n",
       "2              115               0.139               0.028              0.833  \n",
       "3               52               0.193               0.000              0.807  \n",
       "4               88               0.158               0.000              0.842  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_nlp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to file to avoid long processing in the future\n",
    "# features_nlp.to_csv(\"metadata_features.csv.gz\", index=False, compression='gzip', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2703f8c9ab1ac04b22966d975602a3b2e9be2d364f571b124b77afe9344d7a81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
