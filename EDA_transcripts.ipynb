{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files with wrong format:  1\n"
     ]
    }
   ],
   "source": [
    "# Define diretory name\n",
    "directory = \"episode_extracts\"\n",
    "\n",
    "# initiate df and columns\n",
    "transcripts_dataframe = pd.DataFrame()\n",
    "all_eposideid = []\n",
    "all_transcripts = []\n",
    "all_confidence = []\n",
    "faulty_files = 0 # variable for checking how many faulty files\n",
    "\n",
    "# iterate over files in dir\n",
    "for filename in os.scandir(directory):\n",
    "    transcripts = []\n",
    "    confidence = []\n",
    "    try:  # handle problem with files in wrng format (.DS_Store)\n",
    "        with open(filename) as file:\n",
    "            file_content = json.load(file)\n",
    "            # print(json.dumps(file_content, indent = 2, sort_keys=False)) # Print the .json in easy-to-read format (takes a lot of time)\n",
    "            \n",
    "            # index .json and loop at correct indent\n",
    "            results = file_content[\"results\"]\n",
    "            for i in range(len(results)):\n",
    "                # lists are named after their key in the preceeding dict, dicts are named after their order\n",
    "                first_dict = results[i]\n",
    "                alternatives = first_dict[\"alternatives\"]\n",
    "                second_dict = alternatives[0] \n",
    "                if len(second_dict) == 3: # handle problem with empty alternative lists\n",
    "                    transcripts.append(second_dict[\"transcript\"])\n",
    "                    confidence.append(second_dict[\"confidence\"])\n",
    "        \n",
    "        all_eposideid.append(str(filename)[11:-2])\n",
    "        all_transcripts.append(\"\".join(transcripts))\n",
    "        all_confidence.append(np.mean(confidence))\n",
    "    \n",
    "    except:\n",
    "        faulty_files += 1\n",
    "\n",
    "# Print errors message\n",
    "print(\"Number of files with wrong format: \", faulty_files)\n",
    "\n",
    "# Create dataframe\n",
    "transcripts_dataframe[\"episode_id\"] = all_eposideid\n",
    "transcripts_dataframe[\"transcript\"] = all_transcripts\n",
    "transcripts_dataframe[\"avg_confidence\"] = all_confidence # should we do a weighted confidence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_id</th>\n",
       "      <th>transcript</th>\n",
       "      <th>avg_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2MbG3MIGtpDgHsY6nElYVY.json</td>\n",
       "      <td>Yo, yo, yo, it's your boy Coach G from CTN pre...</td>\n",
       "      <td>0.817134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3svkiTkTfcz5APXFWhpgEL.json</td>\n",
       "      <td>Yes, you bet back shade shade. He's back. Tell...</td>\n",
       "      <td>0.841457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0JOymLFsRdeBVZbEA72ayj.json</td>\n",
       "      <td>Hello and welcome to the podcast the first eve...</td>\n",
       "      <td>0.807549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0LM9rb9N4G501Z9vwgVqlC.json</td>\n",
       "      <td>Hello everybody and welcome to another edition...</td>\n",
       "      <td>0.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7LOS9NNPOWOpsUynsjZupo.json</td>\n",
       "      <td>two Pura greetings to you listening around whe...</td>\n",
       "      <td>0.836709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1WosITIkpJemzZaPh8zAVb.json</td>\n",
       "      <td>This is the planetary potential podcast for th...</td>\n",
       "      <td>0.812145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6qv1bIFOAF8COpdxfFTRgT.json</td>\n",
       "      <td>What is up guys? Welcome to a special edition ...</td>\n",
       "      <td>0.815195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>56Cl2iY7KFRVS0QoMlS3u4.json</td>\n",
       "      <td>Hello, you are now listening to The Stoke Hub ...</td>\n",
       "      <td>0.816775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6fykTPFik2hinFgHyk8d0d.json</td>\n",
       "      <td>Welcome to the first episode of PR voices prou...</td>\n",
       "      <td>0.844867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6F9ypi9sRnnM5XUtvcHhpL.json</td>\n",
       "      <td>You know what I did this morning around what's...</td>\n",
       "      <td>0.829023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1FI8PkrUAFs4UZ6UH7frA9.json</td>\n",
       "      <td>Welcome to AP our voices proudly put to by the...</td>\n",
       "      <td>0.825988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0rEooKQ89VcDG7vd006DE3.json</td>\n",
       "      <td>Hello, you are now listening to The Stoke Hub ...</td>\n",
       "      <td>0.794734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7sHyO8wLeEd1LuxfS8AIls.json</td>\n",
       "      <td>Hey, hey. Hey. Hey. Hey, this is your girl Jen...</td>\n",
       "      <td>0.816693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>49wcMBeJfaaL6KFFdsWvac.json</td>\n",
       "      <td>If you haven't heard about anchor is the easie...</td>\n",
       "      <td>0.828960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>399kdfMnjw0KYANZU7CQJ0.json</td>\n",
       "      <td>It's the mother back a podcast. Well that was ...</td>\n",
       "      <td>0.813525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     episode_id  \\\n",
       "0   2MbG3MIGtpDgHsY6nElYVY.json   \n",
       "1   3svkiTkTfcz5APXFWhpgEL.json   \n",
       "2   0JOymLFsRdeBVZbEA72ayj.json   \n",
       "3   0LM9rb9N4G501Z9vwgVqlC.json   \n",
       "4   7LOS9NNPOWOpsUynsjZupo.json   \n",
       "5   1WosITIkpJemzZaPh8zAVb.json   \n",
       "6   6qv1bIFOAF8COpdxfFTRgT.json   \n",
       "7   56Cl2iY7KFRVS0QoMlS3u4.json   \n",
       "8   6fykTPFik2hinFgHyk8d0d.json   \n",
       "9   6F9ypi9sRnnM5XUtvcHhpL.json   \n",
       "10  1FI8PkrUAFs4UZ6UH7frA9.json   \n",
       "11  0rEooKQ89VcDG7vd006DE3.json   \n",
       "12  7sHyO8wLeEd1LuxfS8AIls.json   \n",
       "13  49wcMBeJfaaL6KFFdsWvac.json   \n",
       "14  399kdfMnjw0KYANZU7CQJ0.json   \n",
       "\n",
       "                                           transcript  avg_confidence  \n",
       "0   Yo, yo, yo, it's your boy Coach G from CTN pre...        0.817134  \n",
       "1   Yes, you bet back shade shade. He's back. Tell...        0.841457  \n",
       "2   Hello and welcome to the podcast the first eve...        0.807549  \n",
       "3   Hello everybody and welcome to another edition...        0.816667  \n",
       "4   two Pura greetings to you listening around whe...        0.836709  \n",
       "5   This is the planetary potential podcast for th...        0.812145  \n",
       "6   What is up guys? Welcome to a special edition ...        0.815195  \n",
       "7   Hello, you are now listening to The Stoke Hub ...        0.816775  \n",
       "8   Welcome to the first episode of PR voices prou...        0.844867  \n",
       "9   You know what I did this morning around what's...        0.829023  \n",
       "10  Welcome to AP our voices proudly put to by the...        0.825988  \n",
       "11  Hello, you are now listening to The Stoke Hub ...        0.794734  \n",
       "12  Hey, hey. Hey. Hey. Hey, this is your girl Jen...        0.816693  \n",
       "13  If you haven't heard about anchor is the easie...        0.828960  \n",
       "14  It's the mother back a podcast. Well that was ...        0.813525  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(transcripts_dataframe.shape)\n",
    "transcripts_dataframe.head(transcripts_dataframe.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2703f8c9ab1ac04b22966d975602a3b2e9be2d364f571b124b77afe9344d7a81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
