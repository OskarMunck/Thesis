{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bertopic import BERTopic\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model \n",
    "topic_model = BERTopic.load(\"BERT_v1\")\n",
    "\n",
    "# Load sample data\n",
    "transcripts = pd.read_csv('transcripts_sample_old.csv.gz', compression='gzip')\n",
    "\n",
    "# Create list of transcripts\n",
    "docs = list(transcripts['transcript'])\n",
    "\n",
    "# Get document info\n",
    "topic_doc = topic_model.get_document_info(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello and welcome along to the property Academ...</td>\n",
       "      <td>13</td>\n",
       "      <td>13_filipinos_filipino_hindi_philippines</td>\n",
       "      <td>filipinos - filipino - hindi - philippines - i...</td>\n",
       "      <td>0.382109</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good morning, everyone. This is Trinity here a...</td>\n",
       "      <td>62</td>\n",
       "      <td>62_ginger_deck_tarot_tepper</td>\n",
       "      <td>ginger - deck - tarot - tepper - 2020 - 2019 -...</td>\n",
       "      <td>0.957442</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey guys, it's Peter fry and welcome to the li...</td>\n",
       "      <td>5</td>\n",
       "      <td>5_anchor_podcast_album_weezer</td>\n",
       "      <td>anchor - podcast - album - weezer - song - guy...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>You have turned into functional fun. I'm Mike ...</td>\n",
       "      <td>14</td>\n",
       "      <td>14_insulin_fasting_keto_fat</td>\n",
       "      <td>insulin - fasting - keto - fat - intermittent ...</td>\n",
       "      <td>0.138242</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hey everyone, before we continue with the show...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_anxiety_mental_self_yourself</td>\n",
       "      <td>anxiety - mental - self - yourself - life - de...</td>\n",
       "      <td>0.915268</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document  Topic  \\\n",
       "0  Hello and welcome along to the property Academ...     13   \n",
       "1  Good morning, everyone. This is Trinity here a...     62   \n",
       "2  Hey guys, it's Peter fry and welcome to the li...      5   \n",
       "6  You have turned into functional fun. I'm Mike ...     14   \n",
       "8  Hey everyone, before we continue with the show...      1   \n",
       "\n",
       "                                      Name  \\\n",
       "0  13_filipinos_filipino_hindi_philippines   \n",
       "1              62_ginger_deck_tarot_tepper   \n",
       "2            5_anchor_podcast_album_weezer   \n",
       "6              14_insulin_fasting_keto_fat   \n",
       "8           1_anxiety_mental_self_yourself   \n",
       "\n",
       "                                         Top_n_words  Probability  \\\n",
       "0  filipinos - filipino - hindi - philippines - i...     0.382109   \n",
       "1  ginger - deck - tarot - tepper - 2020 - 2019 -...     0.957442   \n",
       "2  anchor - podcast - album - weezer - song - guy...     1.000000   \n",
       "6  insulin - fasting - keto - fat - intermittent ...     0.138242   \n",
       "8  anxiety - mental - self - yourself - life - de...     0.915268   \n",
       "\n",
       "   Representative_document  \n",
       "0                    False  \n",
       "1                    False  \n",
       "2                    False  \n",
       "6                    False  \n",
       "8                    False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out outliers\n",
    "topic_doc_filter = topic_doc[topic_doc['Topic'] != -1]\n",
    "topic_doc_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 237/237 [15:54<00:00,  4.03s/it]\n"
     ]
    }
   ],
   "source": [
    "# doc_embeddings = topic_model.transform(docs)\n",
    "\n",
    "# Embedd  documents\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = sentence_model.encode(list(topic_doc_filter.Document), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello and welcome along to the property Academ...</td>\n",
       "      <td>13</td>\n",
       "      <td>13_filipinos_filipino_hindi_philippines</td>\n",
       "      <td>filipinos - filipino - hindi - philippines - i...</td>\n",
       "      <td>0.382109</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.05889275, -0.04167155, 0.0474085, 0.0528259...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good morning, everyone. This is Trinity here a...</td>\n",
       "      <td>62</td>\n",
       "      <td>62_ginger_deck_tarot_tepper</td>\n",
       "      <td>ginger - deck - tarot - tepper - 2020 - 2019 -...</td>\n",
       "      <td>0.957442</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.01805721, 0.021562967, 0.10067808, 0.068813...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document  Topic  \\\n",
       "0  Hello and welcome along to the property Academ...     13   \n",
       "1  Good morning, everyone. This is Trinity here a...     62   \n",
       "\n",
       "                                      Name  \\\n",
       "0  13_filipinos_filipino_hindi_philippines   \n",
       "1              62_ginger_deck_tarot_tepper   \n",
       "\n",
       "                                         Top_n_words  Probability  \\\n",
       "0  filipinos - filipino - hindi - philippines - i...     0.382109   \n",
       "1  ginger - deck - tarot - tepper - 2020 - 2019 -...     0.957442   \n",
       "\n",
       "   Representative_document                                         Embeddings  \n",
       "0                    False  [0.05889275, -0.04167155, 0.0474085, 0.0528259...  \n",
       "1                    False  [0.01805721, 0.021562967, 0.10067808, 0.068813...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_doc_filter['Embeddings'] = list(embeddings)\n",
    "topic_doc_filter.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>362</th>\n",
       "      <th>363</th>\n",
       "      <th>364</th>\n",
       "      <th>365</th>\n",
       "      <th>366</th>\n",
       "      <th>367</th>\n",
       "      <th>368</th>\n",
       "      <th>369</th>\n",
       "      <th>370</th>\n",
       "      <th>371</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.325963</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>0.801560</td>\n",
       "      <td>0.579946</td>\n",
       "      <td>0.400170</td>\n",
       "      <td>0.439881</td>\n",
       "      <td>0.778909</td>\n",
       "      <td>0.349178</td>\n",
       "      <td>0.394905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375360</td>\n",
       "      <td>0.074975</td>\n",
       "      <td>0.512340</td>\n",
       "      <td>0.076624</td>\n",
       "      <td>0.645604</td>\n",
       "      <td>0.476304</td>\n",
       "      <td>0.015187</td>\n",
       "      <td>0.381138</td>\n",
       "      <td>0.084565</td>\n",
       "      <td>0.622441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.325963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222527</td>\n",
       "      <td>0.237422</td>\n",
       "      <td>0.296104</td>\n",
       "      <td>0.285267</td>\n",
       "      <td>0.230775</td>\n",
       "      <td>0.171831</td>\n",
       "      <td>0.118418</td>\n",
       "      <td>0.209681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388490</td>\n",
       "      <td>0.122732</td>\n",
       "      <td>0.161230</td>\n",
       "      <td>-0.007268</td>\n",
       "      <td>0.233492</td>\n",
       "      <td>0.318151</td>\n",
       "      <td>0.034612</td>\n",
       "      <td>0.238129</td>\n",
       "      <td>0.057116</td>\n",
       "      <td>0.235031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.435000</td>\n",
       "      <td>0.222527</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.353952</td>\n",
       "      <td>0.532962</td>\n",
       "      <td>0.358618</td>\n",
       "      <td>0.491175</td>\n",
       "      <td>0.297800</td>\n",
       "      <td>0.407624</td>\n",
       "      <td>0.386104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280616</td>\n",
       "      <td>0.158567</td>\n",
       "      <td>0.205688</td>\n",
       "      <td>0.197358</td>\n",
       "      <td>0.453097</td>\n",
       "      <td>0.297102</td>\n",
       "      <td>0.139913</td>\n",
       "      <td>0.338537</td>\n",
       "      <td>0.027177</td>\n",
       "      <td>0.315052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.801560</td>\n",
       "      <td>0.237422</td>\n",
       "      <td>0.353952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565680</td>\n",
       "      <td>0.324068</td>\n",
       "      <td>0.383789</td>\n",
       "      <td>0.781308</td>\n",
       "      <td>0.301149</td>\n",
       "      <td>0.310392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335415</td>\n",
       "      <td>0.024069</td>\n",
       "      <td>0.445647</td>\n",
       "      <td>0.082821</td>\n",
       "      <td>0.548983</td>\n",
       "      <td>0.433539</td>\n",
       "      <td>0.043995</td>\n",
       "      <td>0.304779</td>\n",
       "      <td>0.074871</td>\n",
       "      <td>0.629597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.579946</td>\n",
       "      <td>0.296104</td>\n",
       "      <td>0.532962</td>\n",
       "      <td>0.565680</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.522072</td>\n",
       "      <td>0.572657</td>\n",
       "      <td>0.517597</td>\n",
       "      <td>0.437201</td>\n",
       "      <td>0.422593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464335</td>\n",
       "      <td>0.177808</td>\n",
       "      <td>0.311586</td>\n",
       "      <td>0.227092</td>\n",
       "      <td>0.650440</td>\n",
       "      <td>0.502568</td>\n",
       "      <td>0.235382</td>\n",
       "      <td>0.399114</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>0.527773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>0.476304</td>\n",
       "      <td>0.318151</td>\n",
       "      <td>0.297102</td>\n",
       "      <td>0.433539</td>\n",
       "      <td>0.502568</td>\n",
       "      <td>0.396334</td>\n",
       "      <td>0.353951</td>\n",
       "      <td>0.431497</td>\n",
       "      <td>0.305842</td>\n",
       "      <td>0.363402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511547</td>\n",
       "      <td>0.248596</td>\n",
       "      <td>0.224700</td>\n",
       "      <td>0.044908</td>\n",
       "      <td>0.426623</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.118747</td>\n",
       "      <td>0.184538</td>\n",
       "      <td>0.044857</td>\n",
       "      <td>0.333814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>0.015187</td>\n",
       "      <td>0.034612</td>\n",
       "      <td>0.139913</td>\n",
       "      <td>0.043995</td>\n",
       "      <td>0.235382</td>\n",
       "      <td>0.234381</td>\n",
       "      <td>0.140686</td>\n",
       "      <td>0.044589</td>\n",
       "      <td>0.118343</td>\n",
       "      <td>0.096952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154135</td>\n",
       "      <td>0.218236</td>\n",
       "      <td>0.028612</td>\n",
       "      <td>0.095556</td>\n",
       "      <td>0.231335</td>\n",
       "      <td>0.118747</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.139937</td>\n",
       "      <td>-0.018508</td>\n",
       "      <td>0.043643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0.381138</td>\n",
       "      <td>0.238129</td>\n",
       "      <td>0.338537</td>\n",
       "      <td>0.304779</td>\n",
       "      <td>0.399114</td>\n",
       "      <td>0.405735</td>\n",
       "      <td>0.404301</td>\n",
       "      <td>0.290241</td>\n",
       "      <td>0.282914</td>\n",
       "      <td>0.374211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231758</td>\n",
       "      <td>0.105680</td>\n",
       "      <td>0.302483</td>\n",
       "      <td>0.072165</td>\n",
       "      <td>0.388343</td>\n",
       "      <td>0.184538</td>\n",
       "      <td>0.139937</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170573</td>\n",
       "      <td>0.323585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>0.084565</td>\n",
       "      <td>0.057116</td>\n",
       "      <td>0.027177</td>\n",
       "      <td>0.074871</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>0.126372</td>\n",
       "      <td>0.059775</td>\n",
       "      <td>0.094851</td>\n",
       "      <td>0.059487</td>\n",
       "      <td>0.208809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052848</td>\n",
       "      <td>0.040853</td>\n",
       "      <td>0.137243</td>\n",
       "      <td>0.099333</td>\n",
       "      <td>0.153465</td>\n",
       "      <td>0.044857</td>\n",
       "      <td>-0.018508</td>\n",
       "      <td>0.170573</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.145142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0.622441</td>\n",
       "      <td>0.235031</td>\n",
       "      <td>0.315052</td>\n",
       "      <td>0.629597</td>\n",
       "      <td>0.527773</td>\n",
       "      <td>0.341649</td>\n",
       "      <td>0.380397</td>\n",
       "      <td>0.527344</td>\n",
       "      <td>0.212281</td>\n",
       "      <td>0.279184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343356</td>\n",
       "      <td>0.154947</td>\n",
       "      <td>0.389042</td>\n",
       "      <td>0.134454</td>\n",
       "      <td>0.510984</td>\n",
       "      <td>0.333814</td>\n",
       "      <td>0.043643</td>\n",
       "      <td>0.323585</td>\n",
       "      <td>0.145142</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>372 rows × 372 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    1.000000  0.325963  0.435000  0.801560  0.579946  0.400170  0.439881   \n",
       "1    0.325963  1.000000  0.222527  0.237422  0.296104  0.285267  0.230775   \n",
       "2    0.435000  0.222527  1.000000  0.353952  0.532962  0.358618  0.491175   \n",
       "3    0.801560  0.237422  0.353952  1.000000  0.565680  0.324068  0.383789   \n",
       "4    0.579946  0.296104  0.532962  0.565680  1.000000  0.522072  0.572657   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "367  0.476304  0.318151  0.297102  0.433539  0.502568  0.396334  0.353951   \n",
       "368  0.015187  0.034612  0.139913  0.043995  0.235382  0.234381  0.140686   \n",
       "369  0.381138  0.238129  0.338537  0.304779  0.399114  0.405735  0.404301   \n",
       "370  0.084565  0.057116  0.027177  0.074871  0.083400  0.126372  0.059775   \n",
       "371  0.622441  0.235031  0.315052  0.629597  0.527773  0.341649  0.380397   \n",
       "\n",
       "          7         8         9    ...       362       363       364  \\\n",
       "0    0.778909  0.349178  0.394905  ...  0.375360  0.074975  0.512340   \n",
       "1    0.171831  0.118418  0.209681  ...  0.388490  0.122732  0.161230   \n",
       "2    0.297800  0.407624  0.386104  ...  0.280616  0.158567  0.205688   \n",
       "3    0.781308  0.301149  0.310392  ...  0.335415  0.024069  0.445647   \n",
       "4    0.517597  0.437201  0.422593  ...  0.464335  0.177808  0.311586   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "367  0.431497  0.305842  0.363402  ...  0.511547  0.248596  0.224700   \n",
       "368  0.044589  0.118343  0.096952  ...  0.154135  0.218236  0.028612   \n",
       "369  0.290241  0.282914  0.374211  ...  0.231758  0.105680  0.302483   \n",
       "370  0.094851  0.059487  0.208809  ...  0.052848  0.040853  0.137243   \n",
       "371  0.527344  0.212281  0.279184  ...  0.343356  0.154947  0.389042   \n",
       "\n",
       "          365       366       367       368       369       370       371  \n",
       "0    0.076624  0.645604  0.476304  0.015187  0.381138  0.084565  0.622441  \n",
       "1   -0.007268  0.233492  0.318151  0.034612  0.238129  0.057116  0.235031  \n",
       "2    0.197358  0.453097  0.297102  0.139913  0.338537  0.027177  0.315052  \n",
       "3    0.082821  0.548983  0.433539  0.043995  0.304779  0.074871  0.629597  \n",
       "4    0.227092  0.650440  0.502568  0.235382  0.399114  0.083400  0.527773  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "367  0.044908  0.426623  1.000000  0.118747  0.184538  0.044857  0.333814  \n",
       "368  0.095556  0.231335  0.118747  1.000000  0.139937 -0.018508  0.043643  \n",
       "369  0.072165  0.388343  0.184538  0.139937  1.000000  0.170573  0.323585  \n",
       "370  0.099333  0.153465  0.044857 -0.018508  0.170573  1.000000  0.145142  \n",
       "371  0.134454  0.510984  0.333814  0.043643  0.323585  0.145142  1.000000  \n",
       "\n",
       "[372 rows x 372 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cosine similiarity/distance with document embeddings\n",
    "\n",
    "sim_matrix = cosine_similarity(embeddings)\n",
    "df_sim = pd.DataFrame(sim_matrix, columns=filtered_docs.index, index=filtered_docs.index)\n",
    "df_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (69006, 3)\n"
     ]
    }
   ],
   "source": [
    "# Convert cosine distance matrix to pair-wise dataframe\n",
    "df_tri = pd.DataFrame(np.triu(df_sim), columns=df_sim.columns, index=df_sim.index)\n",
    "df_long = df_tri.stack().reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "df_long.columns = ['Pair_1', 'Pair_2', 'Cosine_Distance']\n",
    "\n",
    "# Remove rows where Pair_1 is equal to Pair_2\n",
    "df_long = df_long[df_long['Pair_1'] != df_long['Pair_2']]\n",
    "df_long = df_long[df_long.Cosine_Distance !=0]\n",
    "\n",
    "print('Shape:', df_long.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret df_long as an edge_weighted graph. Through that we can determine its diameter by finding the maximum edge weight since it is fully connected. \n",
    "diam(G)=max{distG,w(u,v)|u∈V(G),v∈V(G)}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 0.97\n",
      "Min: -0.17\n"
     ]
    }
   ],
   "source": [
    "# Discriptive stats and plot dist\n",
    "print(f'Max: {df_long.Cosine_Distance.max():.2f}')\n",
    "print(f'Min: {df_long.Cosine_Distance.min():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get document embeddings for each topic\n",
    "topic_embeddings = []\n",
    "for topic_id in unique_topics:\n",
    "    docs = topic_doc_filter.Document.where('Topic' == topic_id)\n",
    "    embeddings = topic_model.transform(docs)\n",
    "    topic_embeddings.append(embeddings)\n",
    "\n",
    "# Compute cosine similarity matrix for each topic\n",
    "similarity_matrices = []\n",
    "for embeddings in topic_embeddings:\n",
    "    sim_matrix = cosine_similarity(embeddings)\n",
    "    similarity_matrices.append(sim_matrix)\n",
    "\n",
    "# Create DataFrame to store similarity matrices\n",
    "topic_labels = topic_model.get_topic_freq().index\n",
    "dfs = []\n",
    "for i, sim_matrix in enumerate(similarity_matrices):\n",
    "    topic_label = topic_labels[i]\n",
    "    df = pd.DataFrame(sim_matrix, columns=range(len(topic_model.get_documents(topic_label))),\n",
    "                      index=range(len(topic_model.get_documents(topic_label))))\n",
    "    df.columns = [f'{topic_label}_doc_{idx}' for idx in df.columns]\n",
    "    df.index = [f'{topic_label}_doc_{idx}' for idx in df.index]\n",
    "    dfs.append(df)\n",
    "\n",
    "# Combine similarity matrices for all topics\n",
    "df_cosine_similarities = pd.concat(dfs, axis=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try standardized method - Silhuette score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.046636853"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(silhouette_samples(embeddings, topic_doc_filter.Topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Compute the silhouette scores for each sample\n",
    "sample_silhouette_values = silhouette_samples(embeddings, topic_doc_filter.Topic)\n",
    "silhouette_avg = silhouette_score(embeddings, topic_doc_filter.Topic)\n",
    "\n",
    "\n",
    "y_lower = 10\n",
    "\n",
    "for i in topic_doc_filter.Topic:  #topic_doc_filter.Topic\n",
    "# Aggregate the silhouette scores for samples belonging to\n",
    "# cluster i, and sort them\n",
    "    ith_cluster_silhouette_values = sample_silhouette_values[topic_doc_filter.Topic == i]\n",
    "\n",
    "    ith_cluster_silhouette_values.sort()\n",
    "\n",
    "    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "    y_upper = y_lower + size_cluster_i\n",
    "    plt.ylim([0, len(embeddings) + (2 + 1) * 10])\n",
    "\n",
    "    color = cm.nipy_spectral(float(i) / topic_doc_filter.Topic)\n",
    "    plt.fill_betweenx(\n",
    "        np.arange(y_lower, y_upper),\n",
    "        0,\n",
    "        ith_cluster_silhouette_values,\n",
    "        facecolor=color,\n",
    "        edgecolor=color,\n",
    "        alpha=0.7,)\n",
    "\n",
    "    # Compute the new y_lower for next plot\n",
    "    y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "# Label the silhouette plots with their cluster numbers at the middle\n",
    "plt.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "\n",
    "plt.title(\"The silhouette plot for the various clusters.\")\n",
    "plt.xlabel(\"The silhouette coefficient values\")\n",
    "plt.ylabel(\"Cluster label\")\n",
    "\n",
    "# The vertical line for average silhouette score of all the values\n",
    "plt.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "plt.yticks([])  # Clear the yaxis labels / ticks\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02779929, -0.03583927, -0.02050458, -0.01936856, -0.12648787,\n",
       "       -0.03299312, -0.03313546, -0.02033488, -0.10005478, -0.12449804],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_silhouette_values[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
