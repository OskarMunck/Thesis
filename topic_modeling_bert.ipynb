{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>transcript</th>\n",
       "      <th>avg_confidence</th>\n",
       "      <th>char_count</th>\n",
       "      <th>show_name</th>\n",
       "      <th>show_description</th>\n",
       "      <th>publisher</th>\n",
       "      <th>language</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>episode_description</th>\n",
       "      <th>duration</th>\n",
       "      <th>show_id_trans</th>\n",
       "      <th>category</th>\n",
       "      <th>pubdate</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>show_74R2UD42MRDtmeCGCpXNHA</td>\n",
       "      <td>7tYqM5F5SKtt7lFgcimgAh</td>\n",
       "      <td>I'm Daniel Williams director of active chicks ...</td>\n",
       "      <td>0.850038</td>\n",
       "      <td>11270</td>\n",
       "      <td>Inspire By Dani - The Podcast</td>\n",
       "      <td>Real and raw conversations on mental health, f...</td>\n",
       "      <td>Danielle Williams</td>\n",
       "      <td>['en']</td>\n",
       "      <td>The Best Advice My Mum Ever Gave Me</td>\n",
       "      <td>Today’s Episode I chat about what my mother sa...</td>\n",
       "      <td>13.96255</td>\n",
       "      <td>show_74R2UD42MRDtmeCGCpXNHA</td>\n",
       "      <td>Health &amp; Fitness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>show_4NNO0yIIxzSsZTXR0XnaP7</td>\n",
       "      <td>3gaoEuBYb51UoX7zeqv9yr</td>\n",
       "      <td>We recording KP now. We are recording guys pro...</td>\n",
       "      <td>0.830722</td>\n",
       "      <td>26855</td>\n",
       "      <td>PROJECT MINDSET</td>\n",
       "      <td>PROJECT MINDSET was designed to UPLIFT, INSPIR...</td>\n",
       "      <td>PROJECT MINDSET</td>\n",
       "      <td>['en']</td>\n",
       "      <td>From A.D.D. to GOAT, Selling over a billion in...</td>\n",
       "      <td>From A.D.D. to GOAT, Selling over a billion in...</td>\n",
       "      <td>29.49965</td>\n",
       "      <td>show_4NNO0yIIxzSsZTXR0XnaP7</td>\n",
       "      <td>Business</td>\n",
       "      <td>2019-02-21</td>\n",
       "      <td>5276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       show_id              episode_id  \\\n",
       "0  show_74R2UD42MRDtmeCGCpXNHA  7tYqM5F5SKtt7lFgcimgAh   \n",
       "1  show_4NNO0yIIxzSsZTXR0XnaP7  3gaoEuBYb51UoX7zeqv9yr   \n",
       "\n",
       "                                          transcript  avg_confidence  \\\n",
       "0  I'm Daniel Williams director of active chicks ...        0.850038   \n",
       "1  We recording KP now. We are recording guys pro...        0.830722   \n",
       "\n",
       "   char_count                       show_name  \\\n",
       "0       11270  Inspire By Dani - The Podcast    \n",
       "1       26855                 PROJECT MINDSET   \n",
       "\n",
       "                                    show_description          publisher  \\\n",
       "0  Real and raw conversations on mental health, f...  Danielle Williams   \n",
       "1  PROJECT MINDSET was designed to UPLIFT, INSPIR...    PROJECT MINDSET   \n",
       "\n",
       "  language                                       episode_name  \\\n",
       "0   ['en']               The Best Advice My Mum Ever Gave Me    \n",
       "1   ['en']  From A.D.D. to GOAT, Selling over a billion in...   \n",
       "\n",
       "                                 episode_description  duration  \\\n",
       "0  Today’s Episode I chat about what my mother sa...  13.96255   \n",
       "1  From A.D.D. to GOAT, Selling over a billion in...  29.49965   \n",
       "\n",
       "                 show_id_trans          category     pubdate  word_count  \n",
       "0  show_74R2UD42MRDtmeCGCpXNHA  Health & Fitness         NaN        2259  \n",
       "1  show_4NNO0yIIxzSsZTXR0XnaP7          Business  2019-02-21        5276  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data and check properties\n",
    "transcripts = pd.read_csv('transcripts_sample.csv.gz', compression='gzip')\n",
    "print(transcripts.shape)\n",
    "transcripts.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    }
   ],
   "source": [
    "# Create list of documents as input for BERTopic\n",
    "docs = list(transcripts['transcript'])\n",
    "print(len(docs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define submodels\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "umap_model = UMAP(\n",
    "    n_neighbors=15, \n",
    "    n_components=5, \n",
    "    min_dist=0.0, \n",
    "    metric='cosine')\n",
    "\n",
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size=15, \n",
    "    metric='euclidean', \n",
    "    cluster_selection_method='eom', \n",
    "    prediction_data=True)\n",
    "\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba066f8ecf9d4ee1bd59e04319dd66b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 11:13:38,485 - BERTopic - Transformed documents to Embeddings\n",
      "2023-03-07 11:13:48,761 - BERTopic - Reduced dimensionality\n",
      "2023-03-07 11:13:49,171 - BERTopic - Clustered reduced embeddings\n"
     ]
    }
   ],
   "source": [
    "# Initialize BERTopic and run\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=sentence_model,\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    ctfidf_model=ctfidf_model,\n",
    "    verbose=True  # Might add a progress bar(?)\n",
    "    )\n",
    "\n",
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>6320</td>\n",
       "      <td>-1_things_ve_oh_people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2042</td>\n",
       "      <td>0_anchor_she_podcast_her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>631</td>\n",
       "      <td>1_fucking_shit_song_oh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>446</td>\n",
       "      <td>2_god_jesus_lord_church</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>366</td>\n",
       "      <td>3_police_his_murder_crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>104</td>\n",
       "      <td>16</td>\n",
       "      <td>104_marriage_husband_married_partner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>105</td>\n",
       "      <td>15</td>\n",
       "      <td>105_haunted_voodoo_her_marie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>106</td>\n",
       "      <td>15</td>\n",
       "      <td>106_neighbors_horror_bridge_ozzy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>107</td>\n",
       "      <td>15</td>\n",
       "      <td>107_trading_indicators_trade_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>108</td>\n",
       "      <td>15</td>\n",
       "      <td>108_jitsu_jiu_bjj_belt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                  Name\n",
       "0       -1   6320                -1_things_ve_oh_people\n",
       "1        0   2042              0_anchor_she_podcast_her\n",
       "2        1    631                1_fucking_shit_song_oh\n",
       "3        2    446               2_god_jesus_lord_church\n",
       "4        3    366             3_police_his_murder_crime\n",
       "..     ...    ...                                   ...\n",
       "105    104     16  104_marriage_husband_married_partner\n",
       "106    105     15          105_haunted_voodoo_her_marie\n",
       "107    106     15      106_neighbors_horror_bridge_ozzy\n",
       "108    107     15     107_trading_indicators_trade_risk\n",
       "109    108     15                108_jitsu_jiu_bjj_belt\n",
       "\n",
       "[110 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get topic info on doc level\n",
    "\n",
    "topic_doc = topic_model.get_document_info(docs).sort_values('Probability', ascending=False) # Filter away outlier Topic = -1\n",
    "\n",
    "topic_doc[topic_doc.Topic > -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "topic_model.save(\"BERT_v1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERTtopic V2\n",
    "**Change: smaller documents, same parameter configuration.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(215064, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_id</th>\n",
       "      <th>transcript_subset</th>\n",
       "      <th>sentence_enumerated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7tYqM5F5SKtt7lFgcimgAh</td>\n",
       "      <td>I'm Daniel Williams director of active chicks ...</td>\n",
       "      <td>0 - 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7tYqM5F5SKtt7lFgcimgAh</td>\n",
       "      <td>And when I say, you know, I'm making decisions...</td>\n",
       "      <td>25 - 50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               episode_id                                  transcript_subset  \\\n",
       "0  7tYqM5F5SKtt7lFgcimgAh  I'm Daniel Williams director of active chicks ...   \n",
       "1  7tYqM5F5SKtt7lFgcimgAh  And when I say, you know, I'm making decisions...   \n",
       "\n",
       "  sentence_enumerated  \n",
       "0              0 - 25  \n",
       "1             25 - 50  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_25 = pd.read_csv('sentences_chunkssize_25.csv.gz', usecols=[1,2,3], compression='gzip')\n",
    "print(sentence_25.shape)\n",
    "sentence_25.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215064"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of documents as input for BERTopic\n",
    "docs_sentences = list(sentence_25['transcript_subset'])\n",
    "len(docs_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define submodels\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "umap_model = UMAP(\n",
    "    n_neighbors=15, \n",
    "    n_components=5, \n",
    "    min_dist=0.0, \n",
    "    metric='cosine')\n",
    "\n",
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size=15, \n",
    "    metric='euclidean', \n",
    "    cluster_selection_method='eom', \n",
    "    prediction_data=True)\n",
    "\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa65d8c0f9a43f1bb5bceac3a883702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6721 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize BERTopic and run\n",
    "\n",
    "bert_v2 = BERTopic(\n",
    "    embedding_model=sentence_model,\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    ctfidf_model=ctfidf_model,\n",
    "    verbose=True\n",
    "    )\n",
    "\n",
    "topics, probs = bert_v2.fit_transform(docs_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_v2.save('BERT_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_v2.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "bert_v2 = BERTopic.load('BERT_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_v2.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_v2.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_v2.visualize_topics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT v3\n",
    "**Change: larger documents than v2, 40 sentences per doc, ~620 words. Same paramter configuration.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CREATE BEFORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_40 = pd.read_csv('sentences_chunkssize_40.csv.gz', usecols=[1,2,3], compression='gzip')\n",
    "print(sentence_40.shape)\n",
    "sentence_40.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of documents as input for BERTopic\n",
    "docs_sentences = list(sentence_40['transcript_subset'])\n",
    "len(docs_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define submodels\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "umap_model = UMAP(\n",
    "    n_neighbors=15, \n",
    "    n_components=5, \n",
    "    min_dist=0.0, \n",
    "    metric='cosine')\n",
    "\n",
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size=15, \n",
    "    metric='euclidean', \n",
    "    cluster_selection_method='eom', \n",
    "    prediction_data=True)\n",
    "\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BERTopic and run\n",
    "\n",
    "bert_v3 = BERTopic(\n",
    "    embedding_model=sentence_model,\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    ctfidf_model=ctfidf_model,\n",
    "    verbose=True\n",
    "    )\n",
    "\n",
    "topics, probs = bert_v3.fit_transform(docs_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_v3.save('BERT_v3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
