{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a small BERT to use in pipeline design "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hdbscan import HDBSCAN\n",
    "from bertopic import BERTopic\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.dimensionality import BaseDimensionalityReduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368835\n",
      "5000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "# Load and sample data\n",
    "plain_text = pd.read_csv('sports_word_256.csv.gz', compression='gzip')\n",
    "word_embeddings = np.load('sports_embeddings_256.npy')\n",
    "\n",
    "# sample data\n",
    "sample_index = np.random.choice(word_embeddings.shape[0], 5000, replace=False, random_state=42)\n",
    "plain_text = plain_text.drop(columns='Unnamed: 0')\n",
    "plain_text_sample = plain_text.iloc[list(sample_index),:]\n",
    "documents = plain_text_sample.transcript_subset.to_list()\n",
    "word_embeddings_sample = word_embeddings[sample_index, :]\n",
    "print(len(word_embeddings))\n",
    "print(len(plain_text_sample))\n",
    "print(len(word_embeddings_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA dim reduce\n",
    "PCA = PCA(n_components = 50)\n",
    "PCA_data = PCA.fit_transform(word_embeddings_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE dim reduce\n",
    "t_SNE = TSNE(n_components=3)\n",
    "tsne_data = t_SNE.fit_transform(PCA_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_BERT submodel definition\n",
    "dim_model = BaseDimensionalityReduction()\n",
    "\n",
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size = 15,\n",
    "    metric='euclidean', # same as cosine for normalised data\n",
    "    cluster_selection_method='eom', \n",
    "    prediction_data=True)\n",
    "\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "\n",
    "vectorizer_model = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 14:58:01,658 - BERTopic - The dimensionality reduction algorithm did not contain the `y` parameter and therefore the `y` parameter was not used\n",
      "2023-03-24 14:58:01,661 - BERTopic - Reduced dimensionality\n",
      "2023-03-24 14:58:02,017 - BERTopic - Clustered reduced embeddings\n"
     ]
    }
   ],
   "source": [
    "# pipeline_BERT initialise and run\n",
    "\n",
    "pipeline_BERT = BERTopic(\n",
    "    umap_model=dim_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    ctfidf_model=ctfidf_model,\n",
    "    vectorizer_model = vectorizer_model,\n",
    "    calculate_probabilities=True,\n",
    "    low_memory=True, \n",
    "    verbose=True  # progress bar\n",
    "    ) \n",
    "\n",
    "topics, probs = pipeline_BERT.fit_transform(documents, tsne_data)\n",
    "\n",
    "pipeline_BERT.save('pipeline_BERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pipeline_BERT.get_topics())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
