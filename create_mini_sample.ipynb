{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = pd.read_csv(\"transcripts_dataset_final.csv.gz\", compression=\"gzip\")\n",
    "print(transcripts.shape)\n",
    "transcripts.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for avg_confidence\n",
    "\n",
    "x = transcripts.avg_confidence\n",
    "\n",
    "# Plot the histogram using Matplotlib\n",
    "plt.hist(x, bins=20)\n",
    "plt.title('Histogram of Avg Confidence')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for avg_confidence\n",
    "\n",
    "x = transcripts.word_count\n",
    "\n",
    "# Plot the histogram using Matplotlib\n",
    "plt.hist(x, bins=5)\n",
    "plt.title('Histogram of word count')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for number of transcripts deemed high quality\n",
    "# High quality: Avg confidence > 0.85 and word count > 10000\n",
    "\n",
    "count = len(transcripts.loc[(transcripts.avg_confidence > 0.85) & (transcripts.word_count > 7500)])\n",
    "\n",
    "print(f\"There are {count} instances in the dataframe with both condition1 and condition2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = transcripts.loc[(transcripts.avg_confidence > 0.85) & (transcripts.word_count > 7500)].copy()\n",
    "\n",
    "print(sample.shape)\n",
    "sample.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.show_name.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample.to_csv('transcript_sample_mini.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_split(text):\n",
    "    \"\"\"simple tokeniser\"\"\"\n",
    "    return text.split()\n",
    "\n",
    "# Functions for chunking transcripts on either words or sentences\n",
    "def word_chunk_transcript(transcripts, name_variable='transcript', chunk_size=256):\n",
    "    \"\"\" transcripts: must have two columns - episode_id and tokenised_transcript\n",
    "        chunk_size: number of tokens in chunk \n",
    "    \"\"\"\n",
    "    transcripts[\"tokenised_transcript\"] = transcripts[name_variable].apply(lambda x: tokenize_split(x))\n",
    "\n",
    "    episode_ls = []\n",
    "    transcript_ls = []\n",
    "    words_enum_ls = [] \n",
    "    for index, row in transcripts.iterrows():\n",
    "        for i in range(0, len(row[\"tokenised_transcript\"]), chunk_size):\n",
    "            episode_ls.append(row[\"episode_id\"])\n",
    "            transcript_ls.append(\" \".join(row[\"tokenised_transcript\"][i:i+chunk_size]))\n",
    "            words_enum_ls.append(f\"{i} - {i+chunk_size}\")\n",
    "    word_chunked_df = pd.DataFrame(data = {'episode_id': episode_ls, 'transcript_subset':transcript_ls, 'words_enumerated':words_enum_ls})\n",
    "    return word_chunked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract columns for conversion\n",
    "cols_subset = sample.loc[: ,[\"episode_id\", \"transcript\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_chunk = word_chunk_transcript(cols_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_chunk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = sample_chunk.transcript_subset.to_list()\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import MaximalMarginalRelevance\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA, KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "umap_model = UMAP(\n",
    "    n_neighbors=15, \n",
    "    n_components=5, \n",
    "    min_dist=0.0, \n",
    "    metric='cosine')\n",
    "\n",
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size = 10, # Limit at 400 clusters \n",
    "    metric='euclidean', # same as cosine for normalised data\n",
    "    cluster_selection_method='eom', \n",
    "    prediction_data=True)\n",
    "\n",
    "vectorizer_model = CountVectorizer(min_df=10, stop_words='english', ngram_range=(1,3))\n",
    "\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "\n",
    "representation_model = MaximalMarginalRelevance(diversity=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_mini = sentence_model.encode(docs, convert_to_numpy=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('embeddings_mini.npy', embeddings_mini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_mini = np.load('embeddings_mini.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic(\n",
    "    # embedding_model=sentence_model,\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    ctfidf_model=ctfidf_model,\n",
    "    representation_model=representation_model,\n",
    "    low_memory = True,\n",
    "    calculate_probabilities=True, \n",
    "    verbose=True  # progress bar\n",
    ")\n",
    "\n",
    "topics, probs = topic_model.fit_transform(docs, embeddings_mini)\n",
    "\n",
    "# Save model\n",
    "topic_model.save(\"BERT_mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic.load(\"BERT_mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart(top_n_topics=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = topic_model.topics_\n",
    "proba = topic_model.probabilities_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_int = [i for i in range(len(sample_chunk))]\n",
    "list_of_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_over_time = topic_model.topics_over_time(docs, list_of_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics_over_time(topics_over_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce outliers\n",
    "new_topics = topic_model.reduce_outliers(docs, topics, strategy='distributions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.update_topics(docs, new_topics, top_n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
