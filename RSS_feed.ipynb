{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import feedparser\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"metadata.tsv\", sep= \"\\t\")\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns to the metadata DataFrame\n",
    "metadata['category'] = None\n",
    "metadata['pubdate'] = None\n",
    "\n",
    "# Loop through each row in the metadata DataFrame\n",
    "for index, row in metadata.iterrows():\n",
    "    # Extract the episode_name and episode_uri from the current row\n",
    "    episode_name = row['episode_name']\n",
    "    rss_link = row['rss_link']\n",
    "\n",
    "    # Try to fetch the RSS feed from the episode_uri, and retry up to 3 times if there's an error\n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            feed = feedparser.parse(rss_link)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching RSS feed for {episode_name}: {e}\")\n",
    "            print(f\"Retrying in 20 seconds... (Attempt {attempt+1}/5)\")\n",
    "            time.sleep(20)\n",
    "\n",
    "    # If the maximum number of retries is reached, skip to the next row\n",
    "    else:\n",
    "        print(f\"Max number of retries reached for {episode_name}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Extract the category from the RSS feed's <channel> element\n",
    "    try:\n",
    "        channel = feed.feed\n",
    "        category = channel.tags[0].get('term')\n",
    "    except AttributeError:\n",
    "        category = None\n",
    "\n",
    "    # Loop through each item in the RSS feed\n",
    "    for item in feed.entries:\n",
    "        # Check if the current item's title matches the episode_name\n",
    "        if item.title == episode_name:\n",
    "            # Extract pubdate from the current item and convert to YYYY-MM-DD format\n",
    "            pubdate = parser.parse(item.published).date()\n",
    "\n",
    "            # Update the current row with the fetched data\n",
    "            metadata.at[index, 'category'] = category\n",
    "            metadata.at[index, 'pubdate'] = pubdate\n",
    "            \n",
    "\n",
    "metadata.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save new metadata to file\n",
    "metadata.to_csv('metadata.csv.gz', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_uri</th>\n",
       "      <th>show_name</th>\n",
       "      <th>show_description</th>\n",
       "      <th>publisher</th>\n",
       "      <th>language</th>\n",
       "      <th>rss_link</th>\n",
       "      <th>episode_uri</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>episode_description</th>\n",
       "      <th>duration</th>\n",
       "      <th>show_filename_prefix</th>\n",
       "      <th>episode_filename_prefix</th>\n",
       "      <th>category</th>\n",
       "      <th>pubdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:show:2NYtxEZyYelR6RMKmjfPLB</td>\n",
       "      <td>Kream in your Koffee</td>\n",
       "      <td>A 20-something blunt female takes on the world...</td>\n",
       "      <td>Katie Houle</td>\n",
       "      <td>['en']</td>\n",
       "      <td>https://anchor.fm/s/11b84b68/podcast/rss</td>\n",
       "      <td>spotify:episode:000A9sRBYdVh66csG2qEdj</td>\n",
       "      <td>1: It’s Christmas Time!</td>\n",
       "      <td>On the first ever episode of Kream in your Kof...</td>\n",
       "      <td>12.700133</td>\n",
       "      <td>show_2NYtxEZyYelR6RMKmjfPLB</td>\n",
       "      <td>000A9sRBYdVh66csG2qEdj</td>\n",
       "      <td>Leisure</td>\n",
       "      <td>2019-12-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:show:15iWCbU7QoO23EndPEO6aN</td>\n",
       "      <td>Morning Cup Of Murder</td>\n",
       "      <td>Ever wonder what murder took place on today in...</td>\n",
       "      <td>Morning Cup Of Murder</td>\n",
       "      <td>['en']</td>\n",
       "      <td>https://anchor.fm/s/b07181c/podcast/rss</td>\n",
       "      <td>spotify:episode:000HP8n3hNIfglT2wSI2cA</td>\n",
       "      <td>The Goleta Postal Facility shootings- January ...</td>\n",
       "      <td>See something, say something. It’s a mantra ma...</td>\n",
       "      <td>6.019383</td>\n",
       "      <td>show_15iWCbU7QoO23EndPEO6aN</td>\n",
       "      <td>000HP8n3hNIfglT2wSI2cA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:show:6vZRgUFTYwbAA79UNCADr4</td>\n",
       "      <td>Inside The 18 : A Podcast for Goalkeepers by G...</td>\n",
       "      <td>Inside the 18 is your source for all things Go...</td>\n",
       "      <td>Inside the 18 GK Media</td>\n",
       "      <td>['en']</td>\n",
       "      <td>https://anchor.fm/s/81a072c/podcast/rss</td>\n",
       "      <td>spotify:episode:001UfOruzkA3Bn1SPjcdfa</td>\n",
       "      <td>Ep.36 - Incorporating a Singular Goalkeeping C...</td>\n",
       "      <td>Today’s episode is a sit down Michael and Omar...</td>\n",
       "      <td>43.616333</td>\n",
       "      <td>show_6vZRgUFTYwbAA79UNCADr4</td>\n",
       "      <td>001UfOruzkA3Bn1SPjcdfa</td>\n",
       "      <td>Sports</td>\n",
       "      <td>2019-01-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:show:5BvKEjaMSuvUsGROGi2S7s</td>\n",
       "      <td>Arrowhead Live!</td>\n",
       "      <td>Your favorite podcast for everything @Chiefs! ...</td>\n",
       "      <td>Arrowhead Live!</td>\n",
       "      <td>['en-US']</td>\n",
       "      <td>https://anchor.fm/s/917dba4/podcast/rss</td>\n",
       "      <td>spotify:episode:001i89SvIQgDuuyC53hfBm</td>\n",
       "      <td>Episode 1: Arrowhead Live! Debut</td>\n",
       "      <td>Join us as we take a look at all current Chief...</td>\n",
       "      <td>58.189200</td>\n",
       "      <td>show_5BvKEjaMSuvUsGROGi2S7s</td>\n",
       "      <td>001i89SvIQgDuuyC53hfBm</td>\n",
       "      <td>Sports</td>\n",
       "      <td>2019-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:show:7w3h3umpH74veEJcbE6xf4</td>\n",
       "      <td>FBoL</td>\n",
       "      <td>The comedy podcast about toxic characters, wri...</td>\n",
       "      <td>Emily Edwards</td>\n",
       "      <td>['en']</td>\n",
       "      <td>https://www.fuckboisoflit.com/episodes?format=rss</td>\n",
       "      <td>spotify:episode:0025RWNwe2lnp6HcnfzwzG</td>\n",
       "      <td>The Lion, The Witch, And The Wardrobe - Ashley...</td>\n",
       "      <td>The modern morality tail of how to stay good f...</td>\n",
       "      <td>51.782050</td>\n",
       "      <td>show_7w3h3umpH74veEJcbE6xf4</td>\n",
       "      <td>0025RWNwe2lnp6HcnfzwzG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              show_uri  \\\n",
       "0  spotify:show:2NYtxEZyYelR6RMKmjfPLB   \n",
       "1  spotify:show:15iWCbU7QoO23EndPEO6aN   \n",
       "2  spotify:show:6vZRgUFTYwbAA79UNCADr4   \n",
       "3  spotify:show:5BvKEjaMSuvUsGROGi2S7s   \n",
       "4  spotify:show:7w3h3umpH74veEJcbE6xf4   \n",
       "\n",
       "                                           show_name  \\\n",
       "0                               Kream in your Koffee   \n",
       "1                              Morning Cup Of Murder   \n",
       "2  Inside The 18 : A Podcast for Goalkeepers by G...   \n",
       "3                                    Arrowhead Live!   \n",
       "4                                              FBoL    \n",
       "\n",
       "                                    show_description               publisher  \\\n",
       "0  A 20-something blunt female takes on the world...             Katie Houle   \n",
       "1  Ever wonder what murder took place on today in...   Morning Cup Of Murder   \n",
       "2  Inside the 18 is your source for all things Go...  Inside the 18 GK Media   \n",
       "3  Your favorite podcast for everything @Chiefs! ...         Arrowhead Live!   \n",
       "4  The comedy podcast about toxic characters, wri...           Emily Edwards   \n",
       "\n",
       "    language                                           rss_link  \\\n",
       "0     ['en']           https://anchor.fm/s/11b84b68/podcast/rss   \n",
       "1     ['en']            https://anchor.fm/s/b07181c/podcast/rss   \n",
       "2     ['en']            https://anchor.fm/s/81a072c/podcast/rss   \n",
       "3  ['en-US']            https://anchor.fm/s/917dba4/podcast/rss   \n",
       "4     ['en']  https://www.fuckboisoflit.com/episodes?format=rss   \n",
       "\n",
       "                              episode_uri  \\\n",
       "0  spotify:episode:000A9sRBYdVh66csG2qEdj   \n",
       "1  spotify:episode:000HP8n3hNIfglT2wSI2cA   \n",
       "2  spotify:episode:001UfOruzkA3Bn1SPjcdfa   \n",
       "3  spotify:episode:001i89SvIQgDuuyC53hfBm   \n",
       "4  spotify:episode:0025RWNwe2lnp6HcnfzwzG   \n",
       "\n",
       "                                        episode_name  \\\n",
       "0                            1: It’s Christmas Time!   \n",
       "1  The Goleta Postal Facility shootings- January ...   \n",
       "2  Ep.36 - Incorporating a Singular Goalkeeping C...   \n",
       "3                   Episode 1: Arrowhead Live! Debut   \n",
       "4  The Lion, The Witch, And The Wardrobe - Ashley...   \n",
       "\n",
       "                                 episode_description   duration  \\\n",
       "0  On the first ever episode of Kream in your Kof...  12.700133   \n",
       "1  See something, say something. It’s a mantra ma...   6.019383   \n",
       "2  Today’s episode is a sit down Michael and Omar...  43.616333   \n",
       "3  Join us as we take a look at all current Chief...  58.189200   \n",
       "4  The modern morality tail of how to stay good f...  51.782050   \n",
       "\n",
       "          show_filename_prefix episode_filename_prefix category     pubdate  \n",
       "0  show_2NYtxEZyYelR6RMKmjfPLB  000A9sRBYdVh66csG2qEdj  Leisure  2019-12-18  \n",
       "1  show_15iWCbU7QoO23EndPEO6aN  000HP8n3hNIfglT2wSI2cA      NaN         NaN  \n",
       "2  show_6vZRgUFTYwbAA79UNCADr4  001UfOruzkA3Bn1SPjcdfa   Sports  2019-01-18  \n",
       "3  show_5BvKEjaMSuvUsGROGi2S7s  001i89SvIQgDuuyC53hfBm   Sports  2019-03-01  \n",
       "4  show_7w3h3umpH74veEJcbE6xf4  0025RWNwe2lnp6HcnfzwzG      NaN         NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv('metadata.csv.gz', compression='gzip')\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_err = metadata[metadata.category.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_err.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each row in the metadata DataFrame\n",
    "for index, row in metadata_err.iterrows():\n",
    "    # Extract the episode_name and episode_uri from the current row\n",
    "    episode_name = row['episode_name']\n",
    "    rss_link = row['rss_link']\n",
    "\n",
    "    # Try to fetch the RSS feed from the episode_uri, and retry up to 3 times if there's an error\n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            feed = feedparser.parse(rss_link)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching RSS feed for {episode_name}: {e}\")\n",
    "            print(f\"Retrying in 20 seconds... (Attempt {attempt+1}/5)\")\n",
    "            time.sleep(20)\n",
    "\n",
    "    # If the maximum number of retries is reached, skip to the next row\n",
    "    else:\n",
    "        print(f\"Max number of retries reached for {episode_name}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Extract the category from the RSS feed's <channel> element\n",
    "    try:\n",
    "        channel = feed.feed\n",
    "        category = channel.tags[0].get('term')\n",
    "        # print(category)\n",
    "    except AttributeError:\n",
    "        category = None\n",
    "\n",
    "    # Loop through each item in the RSS feed\n",
    "    for item in feed.entries:\n",
    "        # Check if the current item's title matches the episode_name\n",
    "        if item.title == episode_name:\n",
    "            # Extract pubdate from the current item and convert to YYYY-MM-DD format\n",
    "            pubdate = parser.parse(item.published).date()\n",
    "            # print(pubdate)\n",
    "\n",
    "            # Update the current row with the fetched data\n",
    "            metadata_err.at[index, 'category'] = category\n",
    "            metadata_err.at[index, 'pubdate'] = pubdate\n",
    "            \n",
    "\n",
    "metadata_err.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_err.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
