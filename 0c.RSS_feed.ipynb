{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access RSS feeds and retrive more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import feedparser\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "show_uri                       0\n",
       "show_name                      0\n",
       "show_description               2\n",
       "publisher                      0\n",
       "language                       0\n",
       "rss_link                       0\n",
       "episode_uri                    0\n",
       "episode_name                   0\n",
       "episode_description          205\n",
       "duration                       0\n",
       "show_filename_prefix           0\n",
       "episode_filename_prefix        0\n",
       "category                   30276\n",
       "pubdate                    30266\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv('/Users/ramon.habtezghi/Desktop/THESIS/REPO/Thesis/metadata.csv.gz', compression='gzip')\n",
    "metadata.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30276, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_err = metadata[metadata.category.isna()]\n",
    "metadata_err.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "show_uri                       0\n",
       "show_name                      0\n",
       "show_description               0\n",
       "publisher                      0\n",
       "language                       0\n",
       "rss_link                       0\n",
       "episode_uri                    0\n",
       "episode_name                   0\n",
       "episode_description           65\n",
       "duration                       0\n",
       "show_filename_prefix           0\n",
       "episode_filename_prefix        0\n",
       "category                    6000\n",
       "pubdate                    20030\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loop through each row in the metadata DataFrame\n",
    "for index, row in metadata_err.iterrows():\n",
    "    # Extract the episode_name and episode_uri from the current row\n",
    "    episode_name = row['episode_name'].strip()\n",
    "    rss_link = row['rss_link']\n",
    "\n",
    "    # Try to fetch the RSS feed from the episode_uri, and retry up to 3 times if there's an error\n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            feed = feedparser.parse(rss_link)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching RSS feed for {episode_name}: {e}\")\n",
    "            print(f\"Retrying in 20 seconds... (Attempt {attempt+1}/5)\")\n",
    "            time.sleep(20)\n",
    "\n",
    "    # If the maximum number of retries is reached, skip to the next row\n",
    "    else:\n",
    "        print(f\"Max number of retries reached for {episode_name}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Extract the category from the RSS feed's <channel> element\n",
    "    try:\n",
    "        channel = feed.feed\n",
    "        category = channel.tags[0].get('term')\n",
    "        # Update the current row with the fetched data\n",
    "        metadata_err.at[index, 'category'] = category\n",
    "        # print(category)\n",
    "    except AttributeError:\n",
    "        category = None\n",
    "        continue\n",
    "\n",
    "    # Loop through each item in the RSS feed\n",
    "    for item in feed.entries:\n",
    "        # Check if the current item's title matches the episode_name\n",
    "        if item.title == episode_name:\n",
    "            # Extract pubdate from the current item and convert to YYYY-MM-DD format\n",
    "            pubdate = parser.parse(item.published).date()\n",
    "            # print(pubdate)\n",
    "\n",
    "            # Update the current row with the fetched data\n",
    "            metadata_err.at[index, 'pubdate'] = pubdate            \n",
    "\n",
    "metadata_err.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30276, 14)\n",
      "(105360, 14)\n"
     ]
    }
   ],
   "source": [
    "print(metadata_err.shape)\n",
    "print(metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['show_uri',\n",
       " 'show_name',\n",
       " 'show_description',\n",
       " 'publisher',\n",
       " 'language',\n",
       " 'rss_link',\n",
       " 'episode_uri',\n",
       " 'episode_name',\n",
       " 'episode_description',\n",
       " 'duration',\n",
       " 'show_filename_prefix',\n",
       " 'episode_filename_prefix',\n",
       " 'category',\n",
       " 'pubdate']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(metadata_err.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['show_uri', 'show_name', 'show_description', 'publisher', 'language',\n",
      "       'rss_link', 'episode_uri', 'episode_name', 'episode_description',\n",
      "       'duration', 'show_filename_prefix', 'episode_filename_prefix',\n",
      "       'category_x', 'pubdate_x', 'category_y', 'pubdate_y'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "show_uri                       0\n",
       "show_name                      0\n",
       "show_description               2\n",
       "publisher                      0\n",
       "language                       0\n",
       "rss_link                       0\n",
       "episode_uri                    0\n",
       "episode_name                   0\n",
       "episode_description          205\n",
       "duration                       0\n",
       "show_filename_prefix           0\n",
       "episode_filename_prefix        0\n",
       "category_x                 30276\n",
       "pubdate_x                  30266\n",
       "category_y                 81084\n",
       "pubdate_y                  95114\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the two dataframes based on their common column (id)\n",
    "metadata_merged = pd.merge(metadata, metadata_err, on=\n",
    "                           ['show_uri','show_name','show_description','publisher', 'language','rss_link','episode_uri','episode_name',\n",
    "                            'episode_description','duration','show_filename_prefix','episode_filename_prefix'], how='left')\n",
    "\n",
    "print(metadata_merged.columns)\n",
    "metadata_merged.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "show_uri                       0\n",
       "show_name                      0\n",
       "show_description               2\n",
       "publisher                      0\n",
       "language                       0\n",
       "rss_link                       0\n",
       "episode_uri                    0\n",
       "episode_name                   0\n",
       "episode_description          205\n",
       "duration                       0\n",
       "show_filename_prefix           0\n",
       "episode_filename_prefix        0\n",
       "category                    6000\n",
       "pubdate                    20030\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill the missing values in the merged dataframe with the values from the metadata_err dataframe\n",
    "metadata_merged['category_x'].fillna(metadata_merged['category_y'], inplace=True)\n",
    "metadata_merged['pubdate_x'].fillna(metadata_merged['pubdate_y'], inplace=True)\n",
    "\n",
    "# drop the duplicate columns\n",
    "metadata_merged.drop(['category_y', 'pubdate_y'], axis=1, inplace=True)\n",
    "metadata_merged.rename(columns={'category_x': 'category', 'pubdate_x': 'pubdate'}, inplace=True)\n",
    "\n",
    "# the merged dataframe now contains the missing values from the metadata_err dataframe\n",
    "metadata_merged.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105360, 14)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save new metadata to file\n",
    "metadata_merged.to_csv('metadata.csv.gz', compression='gzip', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
