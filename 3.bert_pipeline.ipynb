{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First step in pipeline\n",
    "**Load HDBSCAN and t-SNE models and find probabilities for all sentences in a document. The output of this file will be used in the segmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import hdbscan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openTSNE import TSNE\n",
    "from bertopic import BERTopic\n",
    "from sklearn.decomposition import PCA\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load PCA class object\n",
    "with open('pca_model_word50.pkl', 'rb') as inp:\n",
    "    PCA_model = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load t-SNE class object\n",
    "with open('word_tsne_data.pkl', 'rb') as inp:\n",
    "    tsne_data = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.98% of the variance has been removed by PCA for transcript 7A7swZJL0AtFghauiGLadV\n",
      "===> Finding 15 nearest neighbors in existing embedding using Annoy approximate search...\n",
      "   --> Time elapsed: 1.99 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.01 seconds\n",
      "===> Running optimization with exaggeration=4.00, lr=0.10 for 0 iterations...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=1.50, lr=0.10 for 250 iterations...\n",
      "Iteration   50, KL divergence 1274.4259, 50 iterations in 17.2795 sec\n",
      "Iteration  100, KL divergence 1226.8112, 50 iterations in 19.3756 sec\n",
      "Iteration  150, KL divergence 1217.9773, 50 iterations in 22.1012 sec\n",
      "Iteration  200, KL divergence 1208.8139, 50 iterations in 19.8186 sec\n",
      "Iteration  250, KL divergence 1202.6663, 50 iterations in 16.8164 sec\n",
      "   --> Time elapsed: 95.39 seconds\n",
      "41.98% of the variance has been removed by PCA for transcript 5Sg6efUjypR4m6p9eYBXpm\n",
      "===> Finding 15 nearest neighbors in existing embedding using Annoy approximate search...\n",
      "   --> Time elapsed: 2.75 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.01 seconds\n",
      "===> Running optimization with exaggeration=4.00, lr=0.10 for 0 iterations...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=1.50, lr=0.10 for 250 iterations...\n",
      "Iteration   50, KL divergence 5191.8446, 50 iterations in 19.0915 sec\n",
      "Iteration  100, KL divergence 5108.0712, 50 iterations in 16.7378 sec\n",
      "Iteration  150, KL divergence 5087.7268, 50 iterations in 18.1561 sec\n",
      "Iteration  200, KL divergence 5082.0638, 50 iterations in 18.4239 sec\n",
      "Iteration  250, KL divergence 5078.2289, 50 iterations in 18.3281 sec\n",
      "   --> Time elapsed: 90.74 seconds\n",
      "41.98% of the variance has been removed by PCA for transcript 3DR5Qa40Mc17AiBYfmC29U\n",
      "===> Finding 15 nearest neighbors in existing embedding using Annoy approximate search...\n",
      "   --> Time elapsed: 1.40 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.01 seconds\n",
      "===> Running optimization with exaggeration=4.00, lr=0.10 for 0 iterations...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=1.50, lr=0.10 for 250 iterations...\n",
      "Iteration   50, KL divergence 2992.6923, 50 iterations in 17.0236 sec\n",
      "Iteration  100, KL divergence 2944.7864, 50 iterations in 16.1224 sec\n",
      "Iteration  150, KL divergence 2920.4897, 50 iterations in 16.5189 sec\n",
      "Iteration  200, KL divergence 2909.4237, 50 iterations in 16.1766 sec\n",
      "Iteration  250, KL divergence 2907.6599, 50 iterations in 16.4041 sec\n",
      "   --> Time elapsed: 82.25 seconds\n",
      "41.98% of the variance has been removed by PCA for transcript 0bXWB28GwN8OiqC1ykRrRX\n",
      "===> Finding 15 nearest neighbors in existing embedding using Annoy approximate search...\n",
      "   --> Time elapsed: 1.02 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.01 seconds\n",
      "===> Running optimization with exaggeration=4.00, lr=0.10 for 0 iterations...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=1.50, lr=0.10 for 250 iterations...\n",
      "Iteration   50, KL divergence 8002.2626, 50 iterations in 17.9514 sec\n",
      "Iteration  100, KL divergence 7860.5668, 50 iterations in 16.4746 sec\n",
      "Iteration  150, KL divergence 7823.7027, 50 iterations in 16.3514 sec\n",
      "Iteration  200, KL divergence 7804.6992, 50 iterations in 16.5498 sec\n",
      "Iteration  250, KL divergence 7796.0547, 50 iterations in 16.4103 sec\n",
      "   --> Time elapsed: 83.74 seconds\n",
      "41.98% of the variance has been removed by PCA for transcript 13NDTKL5ZGs8cb8dojW3bz\n",
      "===> Finding 15 nearest neighbors in existing embedding using Annoy approximate search...\n",
      "   --> Time elapsed: 0.59 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=4.00, lr=0.10 for 0 iterations...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=1.50, lr=0.10 for 250 iterations...\n",
      "Iteration   50, KL divergence 3050.3598, 50 iterations in 16.3524 sec\n",
      "Iteration  100, KL divergence 2989.8366, 50 iterations in 16.4591 sec\n",
      "Iteration  150, KL divergence 2961.0490, 50 iterations in 16.2555 sec\n",
      "Iteration  200, KL divergence 2952.0619, 50 iterations in 16.2871 sec\n",
      "Iteration  250, KL divergence 2949.3688, 50 iterations in 16.3907 sec\n",
      "   --> Time elapsed: 81.75 seconds\n",
      "41.98% of the variance has been removed by PCA for transcript 4DUIcbw3EZpeYUC2mcxV0D\n",
      "===> Finding 15 nearest neighbors in existing embedding using Annoy approximate search...\n",
      "   --> Time elapsed: 0.49 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=4.00, lr=0.10 for 0 iterations...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=1.50, lr=0.10 for 250 iterations...\n",
      "Iteration   50, KL divergence 3148.9993, 50 iterations in 16.1870 sec\n",
      "Iteration  100, KL divergence 3083.4069, 50 iterations in 16.2702 sec\n",
      "Iteration  150, KL divergence 3071.2551, 50 iterations in 16.5964 sec\n",
      "Iteration  200, KL divergence 3067.7333, 50 iterations in 16.5267 sec\n",
      "Iteration  250, KL divergence 3062.9530, 50 iterations in 16.6067 sec\n",
      "   --> Time elapsed: 82.19 seconds\n",
      "41.98% of the variance has been removed by PCA for transcript 5ts4p0QlyePWCgIB2W1wLf\n",
      "===> Finding 15 nearest neighbors in existing embedding using Annoy approximate search...\n",
      "   --> Time elapsed: 0.26 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.01 seconds\n",
      "===> Running optimization with exaggeration=4.00, lr=0.10 for 0 iterations...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=1.50, lr=0.10 for 250 iterations...\n",
      "Iteration   50, KL divergence 3149.5800, 50 iterations in 16.8472 sec\n",
      "Iteration  100, KL divergence 3105.3483, 50 iterations in 16.7017 sec\n",
      "Iteration  150, KL divergence 3091.4160, 50 iterations in 16.6792 sec\n",
      "Iteration  200, KL divergence 3088.7248, 50 iterations in 16.6828 sec\n",
      "Iteration  250, KL divergence 3087.1642, 50 iterations in 17.4560 sec\n",
      "   --> Time elapsed: 84.37 seconds\n",
      "41.98% of the variance has been removed by PCA for transcript 19W5dgUcFseQZBmcVF4coc\n",
      "===> Finding 15 nearest neighbors in existing embedding using Annoy approximate search...\n",
      "   --> Time elapsed: 0.32 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.01 seconds\n",
      "===> Running optimization with exaggeration=4.00, lr=0.10 for 0 iterations...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=1.50, lr=0.10 for 250 iterations...\n",
      "Iteration   50, KL divergence 2592.4787, 50 iterations in 16.5611 sec\n",
      "Iteration  100, KL divergence 2530.0234, 50 iterations in 16.4539 sec\n",
      "Iteration  150, KL divergence 2514.5168, 50 iterations in 16.2874 sec\n",
      "Iteration  200, KL divergence 2500.1988, 50 iterations in 16.1687 sec\n",
      "Iteration  250, KL divergence 2494.7708, 50 iterations in 16.2045 sec\n",
      "   --> Time elapsed: 81.68 seconds\n",
      "41.98% of the variance has been removed by PCA for transcript 3iydyD9rAb1f6rmvmgpwS4\n",
      "===> Finding 15 nearest neighbors in existing embedding using Annoy approximate search...\n",
      "   --> Time elapsed: 0.35 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.01 seconds\n",
      "===> Running optimization with exaggeration=4.00, lr=0.10 for 0 iterations...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=1.50, lr=0.10 for 250 iterations...\n",
      "Iteration   50, KL divergence 6276.9531, 50 iterations in 16.4639 sec\n",
      "Iteration  100, KL divergence 6181.1013, 50 iterations in 16.3299 sec\n",
      "Iteration  150, KL divergence 6141.8143, 50 iterations in 16.2753 sec\n",
      "Iteration  200, KL divergence 6123.9693, 50 iterations in 17.4929 sec\n",
      "Iteration  250, KL divergence 6115.4488, 50 iterations in 16.5953 sec\n",
      "   --> Time elapsed: 83.16 seconds\n",
      "41.98% of the variance has been removed by PCA for transcript 3RT2j2BG8ILNYKjxsNhfvZ\n",
      "===> Finding 15 nearest neighbors in existing embedding using Annoy approximate search...\n",
      "   --> Time elapsed: 0.64 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.01 seconds\n",
      "===> Running optimization with exaggeration=4.00, lr=0.10 for 0 iterations...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=1.50, lr=0.10 for 250 iterations...\n",
      "Iteration   50, KL divergence 5162.5504, 50 iterations in 16.5691 sec\n",
      "Iteration  100, KL divergence 5084.1981, 50 iterations in 16.2935 sec\n",
      "Iteration  150, KL divergence 5054.8247, 50 iterations in 16.3782 sec\n",
      "Iteration  200, KL divergence 5048.7513, 50 iterations in 16.5260 sec\n",
      "Iteration  250, KL divergence 5040.5747, 50 iterations in 16.2956 sec\n",
      "   --> Time elapsed: 82.06 seconds\n",
      "41.98% of the variance has been removed by PCA for transcript 4y67J0Fmgm5L7TPPsUunwo\n",
      "===> Finding 15 nearest neighbors in existing embedding using Annoy approximate search...\n",
      "   --> Time elapsed: 0.99 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.01 seconds\n",
      "===> Running optimization with exaggeration=4.00, lr=0.10 for 0 iterations...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=1.50, lr=0.10 for 250 iterations...\n",
      "Iteration   50, KL divergence 3787.8473, 50 iterations in 21.1300 sec\n",
      "Iteration  100, KL divergence 3700.6442, 50 iterations in 17.5520 sec\n",
      "Iteration  150, KL divergence 3674.9373, 50 iterations in 17.3140 sec\n",
      "Iteration  200, KL divergence 3662.8547, 50 iterations in 15.6627 sec\n",
      "Iteration  250, KL divergence 3660.0972, 50 iterations in 16.6679 sec\n",
      "   --> Time elapsed: 88.33 seconds\n",
      "41.98% of the variance has been removed by PCA for transcript 6preEOWrgR9eRr938upFgv\n",
      "===> Finding 15 nearest neighbors in existing embedding using Annoy approximate search...\n",
      "   --> Time elapsed: 0.70 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.01 seconds\n",
      "===> Running optimization with exaggeration=4.00, lr=0.10 for 0 iterations...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=1.50, lr=0.10 for 250 iterations...\n",
      "Iteration   50, KL divergence 8711.8442, 50 iterations in 16.7519 sec\n",
      "Iteration  100, KL divergence 8536.2451, 50 iterations in 16.4693 sec\n",
      "Iteration  150, KL divergence 8491.6469, 50 iterations in 16.3174 sec\n",
      "Iteration  200, KL divergence 8466.1027, 50 iterations in 16.5328 sec\n",
      "Iteration  250, KL divergence 8455.4711, 50 iterations in 16.2136 sec\n",
      "   --> Time elapsed: 82.29 seconds\n",
      "41.98% of the variance has been removed by PCA for transcript 28IWswylk2FvkebOehoCkL\n",
      "===> Finding 15 nearest neighbors in existing embedding using Annoy approximate search...\n",
      "   --> Time elapsed: 0.31 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.01 seconds\n",
      "===> Running optimization with exaggeration=4.00, lr=0.10 for 0 iterations...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=1.50, lr=0.10 for 250 iterations...\n",
      "Iteration   50, KL divergence 4821.7036, 50 iterations in 20.4510 sec\n",
      "Iteration  100, KL divergence 4743.1091, 50 iterations in 21.7758 sec\n",
      "Iteration  150, KL divergence 4720.5617, 50 iterations in 16.5887 sec\n",
      "Iteration  200, KL divergence 4712.0092, 50 iterations in 16.9040 sec\n",
      "Iteration  250, KL divergence 4709.2265, 50 iterations in 17.3699 sec\n",
      "   --> Time elapsed: 93.09 seconds\n",
      "41.98% of the variance has been removed by PCA for transcript 2Bp5vd9GAmEpZzjEtGQBFD\n",
      "===> Finding 15 nearest neighbors in existing embedding using Annoy approximate search...\n",
      "   --> Time elapsed: 0.11 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=4.00, lr=0.10 for 0 iterations...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=1.50, lr=0.10 for 250 iterations...\n",
      "Iteration   50, KL divergence 603.3407, 50 iterations in 16.2915 sec\n",
      "Iteration  100, KL divergence 596.8615, 50 iterations in 15.8008 sec\n",
      "Iteration  150, KL divergence 590.3327, 50 iterations in 15.5778 sec\n",
      "Iteration  200, KL divergence 588.1390, 50 iterations in 15.2165 sec\n",
      "Iteration  250, KL divergence 587.4399, 50 iterations in 15.7397 sec\n",
      "   --> Time elapsed: 78.63 seconds\n",
      "41.98% of the variance has been removed by PCA for transcript 4pFaG2QLnDr95gqDQFEWoh\n",
      "===> Finding 15 nearest neighbors in existing embedding using Annoy approximate search...\n",
      "   --> Time elapsed: 1.42 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.01 seconds\n",
      "===> Running optimization with exaggeration=4.00, lr=0.10 for 0 iterations...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=1.50, lr=0.10 for 250 iterations...\n",
      "Iteration   50, KL divergence 5471.1853, 50 iterations in 15.3405 sec\n",
      "Iteration  100, KL divergence 5366.7887, 50 iterations in 15.3727 sec\n",
      "Iteration  150, KL divergence 5335.4144, 50 iterations in 14.8330 sec\n",
      "Iteration  200, KL divergence 5327.3843, 50 iterations in 14.8598 sec\n",
      "Iteration  250, KL divergence 5321.5743, 50 iterations in 14.8589 sec\n",
      "   --> Time elapsed: 75.27 seconds\n",
      "41.98% of the variance has been removed by PCA for transcript 53DrbE5nPJskpPT0PtOi9O\n",
      "===> Finding 15 nearest neighbors in existing embedding using Annoy approximate search...\n",
      "   --> Time elapsed: 0.09 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=4.00, lr=0.10 for 0 iterations...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=1.50, lr=0.10 for 250 iterations...\n",
      "Iteration   50, KL divergence 815.7475, 50 iterations in 14.6717 sec\n",
      "Iteration  100, KL divergence 808.1272, 50 iterations in 14.8833 sec\n",
      "Iteration  150, KL divergence 804.7961, 50 iterations in 14.8773 sec\n",
      "Iteration  200, KL divergence 804.6804, 50 iterations in 15.7525 sec\n",
      "Iteration  250, KL divergence 804.6804, 50 iterations in 15.8947 sec\n",
      "   --> Time elapsed: 76.08 seconds\n",
      "41.98% of the variance has been removed by PCA for transcript 0ZGQ63222rqX5TD5ZrMmcN\n",
      "===> Finding 15 nearest neighbors in existing embedding using Annoy approximate search...\n",
      "   --> Time elapsed: 1.49 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.01 seconds\n",
      "===> Running optimization with exaggeration=4.00, lr=0.10 for 0 iterations...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=1.50, lr=0.10 for 250 iterations...\n",
      "Iteration   50, KL divergence 8743.8763, 50 iterations in 16.6620 sec\n",
      "Iteration  100, KL divergence 8599.3257, 50 iterations in 15.8840 sec\n",
      "Iteration  150, KL divergence 8548.2859, 50 iterations in 16.0429 sec\n",
      "Iteration  200, KL divergence 8523.8249, 50 iterations in 15.9433 sec\n",
      "Iteration  250, KL divergence 8511.0590, 50 iterations in 21.0681 sec\n",
      "   --> Time elapsed: 85.60 seconds\n",
      "41.98% of the variance has been removed by PCA for transcript 7mv5E2yb2yVQU34OiQ1vqv\n",
      "===> Finding 15 nearest neighbors in existing embedding using Annoy approximate search...\n",
      "   --> Time elapsed: 0.52 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.01 seconds\n",
      "===> Running optimization with exaggeration=4.00, lr=0.10 for 0 iterations...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=1.50, lr=0.10 for 250 iterations...\n",
      "Iteration   50, KL divergence 10460.7931, 50 iterations in 16.7830 sec\n",
      "Iteration  100, KL divergence 10322.4554, 50 iterations in 14.9699 sec\n",
      "Iteration  150, KL divergence 10288.7660, 50 iterations in 15.0354 sec\n",
      "Iteration  200, KL divergence 10274.3216, 50 iterations in 16.2006 sec\n",
      "Iteration  250, KL divergence 10264.6654, 50 iterations in 16.4652 sec\n",
      "   --> Time elapsed: 79.46 seconds\n",
      "41.98% of the variance has been removed by PCA for transcript 3p9FLEH5V5sCGHhGubaYZc\n",
      "===> Finding 15 nearest neighbors in existing embedding using Annoy approximate search...\n",
      "   --> Time elapsed: 0.08 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=4.00, lr=0.10 for 0 iterations...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=1.50, lr=0.10 for 250 iterations...\n",
      "Iteration   50, KL divergence 2290.5498, 50 iterations in 15.2767 sec\n",
      "Iteration  100, KL divergence 2264.2940, 50 iterations in 14.9041 sec\n",
      "Iteration  150, KL divergence 2252.3318, 50 iterations in 16.2689 sec\n",
      "Iteration  200, KL divergence 2248.9385, 50 iterations in 16.3835 sec\n",
      "Iteration  250, KL divergence 2245.8724, 50 iterations in 16.0769 sec\n",
      "   --> Time elapsed: 78.91 seconds\n",
      "41.98% of the variance has been removed by PCA for transcript 1VBbCB6ja5pPdU2wrBy27N\n",
      "===> Finding 15 nearest neighbors in existing embedding using Annoy approximate search...\n",
      "   --> Time elapsed: 0.77 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.01 seconds\n",
      "===> Running optimization with exaggeration=4.00, lr=0.10 for 0 iterations...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=1.50, lr=0.10 for 250 iterations...\n",
      "Iteration   50, KL divergence 8143.0609, 50 iterations in 15.9434 sec\n",
      "Iteration  100, KL divergence 7991.2760, 50 iterations in 16.0741 sec\n",
      "Iteration  150, KL divergence 7953.7027, 50 iterations in 15.8716 sec\n",
      "Iteration  200, KL divergence 7934.0124, 50 iterations in 15.9106 sec\n",
      "Iteration  250, KL divergence 7922.1693, 50 iterations in 15.8736 sec\n",
      "   --> Time elapsed: 79.67 seconds\n"
     ]
    }
   ],
   "source": [
    "# loop through all of the annotated transcripts and save dim reduced vectors\n",
    "directory = '../Thesis/annotated_transcripts_input'\n",
    "\n",
    "for dirpath, _, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        episode_id = file.split('_')[0]\n",
    "        path = os.path.join(dirpath, file)\n",
    "        with open(path, errors='replace') as f: \n",
    "            prediction_documents = pd.read_csv(f)\n",
    "            docs = prediction_documents.transcript_subset\n",
    "\n",
    "            # embedd\n",
    "            sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "            embedded_sentences = sentence_model.encode(docs)\n",
    "\n",
    "            # reduce dimensions with PCA and t-SNE\n",
    "            PCA_data = PCA_model.transform(embedded_sentences)\n",
    "            print(f\"{1-sum(PCA_model.explained_variance_ratio_):.2%} of the variance has been removed by PCA for transcript {episode_id}\")\n",
    "            tsne_prediction = tsne_data.transform(PCA_data)\n",
    "\n",
    "            # Write transcripts to files\n",
    "            save_path = '../Thesis/annotated_dimreduced/'\n",
    "            name_of_file = f'dimreduced_word50_{episode_id}.npy'\n",
    "            complete_path = os.path.join(save_path, name_of_file)\n",
    "            np.save(complete_path, tsne_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cluster model\n",
    "with open('word50_hdbscan_model.pkl', 'rb') as inp:\n",
    "    hdbscan_model = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Thesis/thesisenv/lib/python3.10/site-packages/numpy/core/_methods.py:38\u001b[0m, in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     32\u001b[0m     _complex_to_float\u001b[39m.\u001b[39mupdate({\n\u001b[1;32m     33\u001b[0m         nt\u001b[39m.\u001b[39mdtype(nt\u001b[39m.\u001b[39mclongdouble) : nt\u001b[39m.\u001b[39mdtype(nt\u001b[39m.\u001b[39mlongdouble),\n\u001b[1;32m     34\u001b[0m     })\n\u001b[1;32m     36\u001b[0m \u001b[39m# avoid keyword arguments to speed up parsing, saves about 15%-20% for very\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m# small reductions\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_amax\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     39\u001b[0m           initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     40\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_maximum(a, axis, \u001b[39mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_amin\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     43\u001b[0m           initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'hdbscan._prediction_utils.prob_in_some_cluster'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/oskarmunckafrosenschold/Documents/Thesis/thesisenv/lib/python3.10/site-packages/numpy/core/_methods.py\", line 38, in _amax\n",
      "    def _amax(a, axis=None, out=None, keepdims=False,\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m tsne_prediction \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(path)\n\u001b[1;32m     10\u001b[0m \u001b[39m# get probability vectors for each cluster via soft clustering\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m probabilities \u001b[39m=\u001b[39m hdbscan\u001b[39m.\u001b[39;49mmembership_vector(hdbscan_model, tsne_prediction)\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnrows: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(probabilities)\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mncols: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(probabilities[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[39m# remedy HDBSCAN problem\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Thesis/thesisenv/lib/python3.10/site-packages/hdbscan/prediction.py:581\u001b[0m, in \u001b[0;36mmembership_vector\u001b[0;34m(clusterer, points_to_predict)\u001b[0m\n\u001b[1;32m    575\u001b[0m     lambda_ \u001b[39m=\u001b[39m neighbor_tree_row[\u001b[39m'\u001b[39m\u001b[39mlambda_val\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    577\u001b[0m distance_vec \u001b[39m=\u001b[39m dist_membership_vector(\n\u001b[1;32m    578\u001b[0m     points_to_predict[i],\n\u001b[1;32m    579\u001b[0m     clusterer\u001b[39m.\u001b[39mprediction_data_\u001b[39m.\u001b[39mexemplars,\n\u001b[1;32m    580\u001b[0m     clusterer\u001b[39m.\u001b[39mprediction_data_\u001b[39m.\u001b[39mdist_metric)\n\u001b[0;32m--> 581\u001b[0m outlier_vec \u001b[39m=\u001b[39m outlier_membership_vector(\n\u001b[1;32m    582\u001b[0m     nearest_neighbor,\n\u001b[1;32m    583\u001b[0m     lambda_,\n\u001b[1;32m    584\u001b[0m     clusters,\n\u001b[1;32m    585\u001b[0m     clusterer\u001b[39m.\u001b[39;49mcondensed_tree_\u001b[39m.\u001b[39;49m_raw_tree,\n\u001b[1;32m    586\u001b[0m     clusterer\u001b[39m.\u001b[39;49mprediction_data_\u001b[39m.\u001b[39;49mleaf_max_lambdas,\n\u001b[1;32m    587\u001b[0m     clusterer\u001b[39m.\u001b[39;49mprediction_data_\u001b[39m.\u001b[39;49mcluster_tree)\n\u001b[1;32m    589\u001b[0m result[i] \u001b[39m=\u001b[39m distance_vec \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m outlier_vec \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2.0\u001b[39m\n\u001b[1;32m    590\u001b[0m result[i] \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m result[i]\u001b[39m.\u001b[39msum()\n",
      "File \u001b[0;32mhdbscan/_prediction_utils.pyx:242\u001b[0m, in \u001b[0;36mhdbscan._prediction_utils.outlier_membership_vector\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mhdbscan/_prediction_utils.pyx:253\u001b[0m, in \u001b[0;36mhdbscan._prediction_utils.outlier_membership_vector\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mnanmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# loop through all of the annotated dim reduced embeddings and save topic probability density vector\n",
    "dir = '../Thesis/annotated_dimreduced'\n",
    "\n",
    "for dirpath, _, files in os.walk(dir):\n",
    "    for file in files:\n",
    "        episode_id = file.split('_')[2]\n",
    "        path = os.path.join(dirpath, file)\n",
    "        tsne_prediction = np.load(path)\n",
    "\n",
    "        # get probability vectors for each cluster via soft clustering\n",
    "        probabilities = hdbscan.membership_vector(hdbscan_model, tsne_prediction)\n",
    "        print(f'nrows: {len(probabilities)}\\nncols: {len(probabilities[0])}')\n",
    "        # remedy HDBSCAN problem\n",
    "        inds = np.where(np.isnan(probabilities))\n",
    "        probabilities[inds] = 0\n",
    "        print(f\"Number of nan rows: {len(set(list(inds[:][0])))} for {episode_id}\\n\\n\")\n",
    "\n",
    "        # save probabilities to use in downstream segmentation\n",
    "        name_of_file = f'../Thesis/annotated_probabilities/topic_probability_density_vector_{episode_id}'\n",
    "        np.save(name_of_file, probabilities)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for individual transcript predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe of one transcript with sentences as instances\n",
    "sentences = pd.read_csv('first_podcast.csv.gz', compression='gzip')\n",
    "documents = sentences.transcript_subset.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedd\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embedded_sentences = sentence_model.encode(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.83% of the variance has been removed by PCA\n",
      "===> Finding 15 nearest neighbors in existing embedding using Annoy approximate search...\n",
      "   --> Time elapsed: 11.78 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.03 seconds\n",
      "===> Running optimization with exaggeration=4.00, lr=0.10 for 0 iterations...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=1.50, lr=0.10 for 250 iterations...\n",
      "Iteration   50, KL divergence 9527.4070, 50 iterations in 70.7268 sec\n",
      "Iteration  100, KL divergence 9287.1780, 50 iterations in 92.7301 sec\n",
      "Iteration  150, KL divergence 9191.3463, 50 iterations in 104.2941 sec\n",
      "Iteration  200, KL divergence 9151.7852, 50 iterations in 87.6444 sec\n",
      "Iteration  250, KL divergence 9132.1676, 50 iterations in 86.1700 sec\n",
      "   --> Time elapsed: 441.57 seconds\n"
     ]
    }
   ],
   "source": [
    "# reduce dimensions with PCA and t-SNE\n",
    "PCA_model = PCA(n_components = 50)\n",
    "PCA_data = PCA_model.fit_transform(embedded_sentences)\n",
    "print(f\"{1-sum(PCA_model.explained_variance_ratio_):.2%} of the variance has been removed by PCA\")\n",
    "\n",
    "tsne_test = tsne_data.transform(PCA_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oskarmunckafrosenschold/Documents/Thesis/thesisenv/lib/python3.10/site-packages/hdbscan/prediction.py:581: RuntimeWarning: All-NaN slice encountered\n",
      "  outlier_vec = outlier_membership_vector(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrows: 599\n",
      "ncols: 156\n"
     ]
    }
   ],
   "source": [
    "# get probability vectors for each cluster via soft clustering\n",
    "probabilities = hdbscan.membership_vector(hdbscan_model, tsne_test)\n",
    "print(f'nrows: {len(probabilities)}')\n",
    "print(f'ncols: {len(probabilities[0])}')\n",
    "# remedy for HDBSCAN problem\n",
    "inds = np.where(np.isnan(probabilities))\n",
    "probabilities[inds] = 0\n",
    "print(f\"Number of nan rows: {len(set(list(inds[:][0])))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save probabilities to use in segmentation\n",
    "np.save('probabilities.npy', probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
